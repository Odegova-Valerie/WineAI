{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9D_WNHUdWdSW",
        "ClbHv28CXNWu",
        "5RUUYh0dXc_E",
        "NiB_N6vEXl8E",
        "ZgYn-6KPXw8T",
        "nlMEsSGmYWEy",
        "2DQ62X2nYrqt",
        "Fe5Xj7N3ZUvJ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Uploading files to collab"
      ],
      "metadata": {
        "id": "9D_WNHUdWdSW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81Pd5gDHWR1B"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "id": "3qT6iugUWjNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "7RBIXupTWlBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.remove('data_for_ML_unn.xlsx')"
      ],
      "metadata": {
        "id": "gD96wlLBWnBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "Z2mdn52BWom9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap"
      ],
      "metadata": {
        "id": "rUKvzeD7WqEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "id": "Hw1XpStSWqTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVR\n",
        "from skopt import BayesSearchCV\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from skopt.space import Integer, Real, Categorical\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from xgboost import XGBRegressor\n",
        "import shap\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "hR9YL8q0WxJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML"
      ],
      "metadata": {
        "id": "kSF830oXW2u5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Preparation"
      ],
      "metadata": {
        "id": "eEUz6gyGXDm8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. Working with the table"
      ],
      "metadata": {
        "id": "ClbHv28CXNWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We move the predicted column to the end for convenience\n",
        "db_2 = pd.read_excel('data_for_ML_unn.xlsx')\n",
        "db_1 = db_2.drop(columns=['Sugar_encoded'])\n",
        "db_1.insert(50, 'Sugar_encoded', db_2['Sugar_encoded'])\n",
        "db_final = db_1.drop(columns=['Wine_strength'])\n",
        "db_final.insert(0, 'Wine_strength', db_1['Wine_strength'])"
      ],
      "metadata": {
        "id": "9ZDEBTnvW--0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colors = ['#a5678e','#e8b7d4', '#beb7d9', '#7eabd4', '#31539d'] # Palette of colors"
      ],
      "metadata": {
        "id": "M-zMyKArXXGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Summary table description\n",
        "db_final.describe()"
      ],
      "metadata": {
        "id": "jrKEYAT9XX1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2. Splitting data into test and train"
      ],
      "metadata": {
        "id": "5RUUYh0dXc_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A function for splitting data so that different systems appear in the test and train sample\n",
        "def separation(x,y,n_splits,test_size):\n",
        "    separation = []\n",
        "    k_fold = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=42)\n",
        "    for train_idx, test_idx in k_fold.split(x, y):\n",
        "        separation.append((train_idx, test_idx))\n",
        "    return separation"
      ],
      "metadata": {
        "id": "CWwXYmQ0XhAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We split the sample so that there are different systems in the test and training\n",
        "y = db_final.loc[:,'Sugar_encoded']\n",
        "x = db_final.loc[:,'1_vec_1':]\n",
        "cv = separation(x, y, 1, 0.2)\n",
        "for train_idx, val_idx in cv:\n",
        "    x_train, x_test = x.iloc[train_idx], x.iloc[val_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[val_idx]"
      ],
      "metadata": {
        "id": "4uvKZyUqXjxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3. Functions for plotting and calculating metrics"
      ],
      "metadata": {
        "id": "NiB_N6vEXl8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's introduce a function for calculating metrics\n",
        "def metrics(regr, x_train, y_train, y_test, y_pred, y1_pred):\n",
        "    #Calculation of metrics\n",
        "    F1 = f1_score(y_test, y_pred, average='micro')\n",
        "    F1_train = f1_score(y_train, y1_pred, average='micro')\n",
        "    Accuracy = balanced_accuracy_score(y_test, y_pred)\n",
        "    Accuracy_train = balanced_accuracy_score(y_train, y1_pred)\n",
        "    #print('Q2:', Q2)\n",
        "    #Metrics output\n",
        "    print('f1_score:', F1)\n",
        "    print('Accuracy:', Accuracy)\n",
        "    print('f1_train:', F1_train)\n",
        "    print('Accuracy_train:', Accuracy_train)\n",
        "    return [F1_train, F1, Accuracy_train, Accuracy]"
      ],
      "metadata": {
        "id": "pcEBZSqvXpMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Random Forest Regression"
      ],
      "metadata": {
        "id": "ZgYn-6KPXw8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We optimize for RFR\n",
        "regr_RFR = RandomForestClassifier()\n",
        "\n",
        "search_space = {\"n_estimators\": Integer(50,400),\n",
        "    \"criterion\": Categorical(['squared_error', 'absolute_error']),\n",
        "    \"min_samples_split\": Real(0.01, 0.6),\n",
        "    \"min_samples_leaf\": Real(0.01, 0.5),\n",
        "    \"max_depth\": Integer(1, 12),\n",
        "    \"max_features\": Integer(3, 24)}\n",
        "\n",
        "#Scaling the data\n",
        "sc = MinMaxScaler(feature_range=(0, 1))\n",
        "x_train01 = sc.fit_transform(x_model)\n",
        "opt_RFR = BayesSearchCV(estimator = regr_RFR, search_spaces=search_space, cv = separation(x_model, y_model, 5, 0.2), n_iter=32, verbose=2, n_jobs=-1)\n",
        "opt_RFR.fit(x_train01, y_model)\n",
        "\n",
        "n_esti = opt_RFR.best_estimator_.n_estimators\n",
        "criterion = opt_RFR.best_estimator_.criterion\n",
        "min_leaf = opt_RFR.best_estimator_.min_samples_leaf\n",
        "min_split = opt_RFR.best_estimator_.min_samples_split\n",
        "depth = opt_RFR.best_estimator_.max_depth\n",
        "max_feat = opt_RFR.best_estimator_.max_features\n",
        "\n",
        "print('n_esti:', n_esti,'depth:', depth, 'criterion:', criterion, 'min_leaf:', min_leaf,'min_split:', min_split,'max_feat:', max_feat)"
      ],
      "metadata": {
        "id": "PmRIyK-YX55y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "df_error_train = pd.DataFrame()\n",
        "x_model = x_train.copy().drop(['Sugar_encoded'],axis=1)\n",
        "\n",
        "y_model = y_train.copy()\n",
        "cv = separation(x_model, y_model, 5, 0.2)\n",
        "count = 0\n",
        "\n",
        "#Creating a table to check accuracy on different DES classes\n",
        "RFR_df = x_model[:]\n",
        "RFR_df['Sugar'] = y_model\n",
        "\n",
        "for train_idx, val_idx in cv:\n",
        "    x_train_mod, x_test_mod = x_model.iloc[train_idx], x_model.iloc[val_idx]\n",
        "    y_train_mod, y_test_mod = y_model.iloc[train_idx], y_model.iloc[val_idx]\n",
        "\n",
        "    #Scaling the data\n",
        "    sc = MinMaxScaler(feature_range=(0, 1))\n",
        "    x_train_mod = sc.fit_transform(x_train_mod)\n",
        "    x_test_mod = sc.transform(x_test_mod)\n",
        "    #Random Forest Regression\n",
        "    regr_RFR = RandomForestClassifier()\n",
        "    # regr_RFR = RandomForestClassifier(n_estimators=n_esti, max_depth=depth, min_samples_leaf=min_leaf,\n",
        "    #                              min_samples_split=min_split, criterion=criterion, max_features=max_feat)\n",
        "    regr_RFR.fit(x_train_mod, y_train_mod)\n",
        "    y_pred = regr_RFR.predict(x_test_mod)\n",
        "    y1_pred = regr_RFR.predict(x_train_mod)\n",
        "    #Filling in the table in accordance with the metrics\n",
        "    RFR_df['Sugar_train' + str(count)] = None\n",
        "    RFR_df['Sugar_test' + str(count)] = None\n",
        "    RFR_df['Sugar_train' + str(count)].iloc[train_idx] = y1_pred\n",
        "    RFR_df['Sugar_test' + str(count)].iloc[val_idx] = y_pred\n",
        "    #Calculating metrics\n",
        "    df_error_train['Random Forest Regression' + str(count)] = metrics(regr_RFR, x_train_mod, y_train_mod, y_test_mod, y_pred, y1_pred)\n",
        "    count +=1\n",
        "df_error_train"
      ],
      "metadata": {
        "id": "U7Wqx1yjYDXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Gradient Boosting Regression"
      ],
      "metadata": {
        "id": "nlMEsSGmYWEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We optimize for GBR\n",
        "regr_GBR = GradientBoostingClassifier()\n",
        "\n",
        "search_space = {\"learning_rate\": Real(0.05, 0.15),\n",
        "    \"n_estimators\": Integer(50, 400),\n",
        "    \"max_depth\": Integer(1, 6),\n",
        "    \"min_samples_leaf\": Real(0.05, 0.5),\n",
        "    \"min_samples_split\": Real(0.02, 0.6)}\n",
        "\n",
        "#Scaling the data\n",
        "sc = MinMaxScaler(feature_range=(0, 1))\n",
        "x_train01 = sc.fit_transform(x_model)\n",
        "\n",
        "opt_GBR = BayesSearchCV(estimator = regr_GBR, search_spaces=search_space, cv=separation(x_model, y_model,5, 0.2), n_iter=32, verbose=2, n_jobs=-1)\n",
        "opt_GBR.fit(x_train01, y_model)\n",
        "\n",
        "learning_rate = opt_GBR.best_estimator_.learning_rate\n",
        "n_estimators = opt_GBR.best_estimator_.n_estimators\n",
        "max_depth = opt_GBR.best_estimator_.max_depth\n",
        "min_samples_leaf = opt_GBR.best_estimator_.min_samples_leaf\n",
        "min_samples_split = opt_GBR.best_estimator_.min_samples_split\n",
        "\n",
        "print('learning_rate:', learning_rate,'n_estimators:', n_estimators, 'max_depth:', max_depth, 'min_samples_leaf:', min_samples_leaf,'min_samples_split:', min_samples_split)"
      ],
      "metadata": {
        "id": "heBmRc6QYf1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "#Creating a table to check accuracy on different DES classes\n",
        "GBR_df = x_model[:]\n",
        "GBR_df['Sugar'] = y_model\n",
        "\n",
        "for train_idx, val_idx in cv:\n",
        "    x_train_mod, x_test_mod = x_model.iloc[train_idx], x_model.iloc[val_idx]\n",
        "    y_train_mod, y_test_mod = y_model.iloc[train_idx], y_model.iloc[val_idx]\n",
        "\n",
        "    #Scaling the data\n",
        "    sc = MinMaxScaler(feature_range=(0, 1))\n",
        "    x_train_mod = sc.fit_transform(x_train_mod)\n",
        "    x_test_mod = sc.transform(x_test_mod)\n",
        "    #GBR\n",
        "    regr_GBR = GradientBoostingClassifier()\n",
        "    # regr_GBR = GradientBoostingClassifier(learning_rate = learning_rate, n_estimators = n_estimators, max_depth= max_depth, min_samples_leaf= min_samples_leaf, min_samples_split= min_samples_split)\n",
        "    regr_GBR.fit(x_train_mod, y_train_mod)\n",
        "    y_pred = regr_GBR.predict(x_test_mod)\n",
        "    y1_pred = regr_GBR.predict(x_train_mod)\n",
        "    #Filling in the table in accordance with the metrics\n",
        "    GBR_df['Sugar_train' + str(count)] = None\n",
        "    GBR_df['Sugar_test' + str(count)] = None\n",
        "    GBR_df['Sugar_train' + str(count)].iloc[train_idx] = y1_pred\n",
        "    GBR_df['Sugar_test' + str(count)].iloc[val_idx] = y_pred\n",
        "    #Calculating metrics\n",
        "    df_error_train['Gradient Boosting Regression' + str(count)] = metrics(regr_GBR, x_train_mod, y_train_mod, y_test_mod, y_pred, y1_pred)\n",
        "    count +=1\n",
        "df_error_train"
      ],
      "metadata": {
        "id": "WN1DQNmsYnk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Cat Boosting Regression"
      ],
      "metadata": {
        "id": "2DQ62X2nYrqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Не заработало\n",
        "\n",
        "ValueError: shape mismatch: value array of shape (9208,1) could not be broadcast to indexing result of shape (9208,)"
      ],
      "metadata": {
        "id": "AmtMHUCgY1FY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We optimize for CBR\n",
        "regr_CBR = CatBoostClassifier()\n",
        "\n",
        "search_space = {\"iterations\": Integer(100, 600),\n",
        "                \"learning_rate\": Real(0.05, 0.4),\n",
        "                \"depth\": Integer(1, 6)}\n",
        "\n",
        "#Scaling the data\n",
        "sc = MinMaxScaler(feature_range=(0, 1))\n",
        "x_train01 = sc.fit_transform(x_model)\n",
        "\n",
        "opt_CBR = BayesSearchCV(estimator = regr_CBR, search_spaces=search_space, cv=peparation(x_model, y_model, 5, 0.2), n_iter=32, verbose=2, n_jobs=-1)\n",
        "opt_CBR.fit(x_train01, y_model)\n",
        "\n",
        "iterations = opt_CBR.best_params_['iterations']\n",
        "learning_rate = opt_CBR.best_params_['learning_rate']\n",
        "depth = opt_CBR.best_params_['depth']\n",
        "\n",
        "\n",
        "print('iterations:', iterations,'learning_rate:', learning_rate, 'depth:', depth)"
      ],
      "metadata": {
        "id": "7IL0RLQqYyUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "df_error_train = pd.DataFrame()\n",
        "x_model = x_train.copy().drop(['Sugar_encoded'],axis=1)\n",
        "\n",
        "y_model = y_train.copy()\n",
        "cv = separation(x_model, y_model, 5, 0.2)\n",
        "count = 0\n",
        "\n",
        "#Creating a table to check accuracy on different DES classes\n",
        "RFR_df = x_model[:]\n",
        "RFR_df['Sugar'] = y_model\n",
        "\n",
        "for train_idx, val_idx in cv:\n",
        "    x_train_mod, x_test_mod = x_model.iloc[train_idx], x_model.iloc[val_idx]\n",
        "    y_train_mod, y_test_mod = y_model.iloc[train_idx], y_model.iloc[val_idx]\n",
        "\n",
        "    #Scaling the data\n",
        "    sc = MinMaxScaler(feature_range=(0, 1))\n",
        "    x_train_mod = sc.fit_transform(x_train_mod)\n",
        "    x_test_mod = sc.transform(x_test_mod)\n",
        "    #CBR\n",
        "    regr_CBR = CatBoostClassifier()\n",
        "    # regr_CBR = CatBoostClassifier(iterations = iterations, learning_rate = learning_rate, depth = depth)\n",
        "    regr_CBR.fit(x_train_mod, y_train_mod)\n",
        "    y_pred = regr_CBR.predict(x_test_mod)\n",
        "    y1_pred = regr_CBR.predict(x_train_mod)\n",
        "    #Filling in the table in accordance with the metrics\n",
        "    CBR_df['Sugar_train' + str(count)] = None\n",
        "    CBR_df['Sugar_test' + str(count)] = None\n",
        "    CBR_df['Sugar_train' + str(count)].iloc[train_idx] = y1_pred\n",
        "    CBR_df['Sugar_test' + str(count)].iloc[val_idx] = y_pred\n",
        "    #Calculating metrics\n",
        "    df_error_train['Cat Boosting Regression' + str(count)] = metrics(regr_CBR, x_train_mod, y_train_mod, y_test_mod, y_pred, y1_pred)\n",
        "    count +=1\n",
        "df_error_train"
      ],
      "metadata": {
        "id": "zXnvioQuY8wE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Extreme Gradient Boosting (XGBoost)"
      ],
      "metadata": {
        "id": "Fe5Xj7N3ZUvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We optimize for XGB\n",
        "regr_XGB = XGBClassifier()\n",
        "\n",
        "search_space = {\"n_estimators\": Integer(50, 350),\n",
        "    \"max_depth\": Integer(2, 30),\n",
        "    \"subsample\": Real(0.05, 1.0),\n",
        "    \"colsample_bytree\": Real(0.05, 1.0)}\n",
        "\n",
        "#Scaling the data\n",
        "sc = MinMaxScaler(feature_range=(0, 1))\n",
        "x_train01 = sc.fit_transform(x_model)\n",
        "opt_XGB = BayesSearchCV(estimator = regr_XGB, search_spaces=search_space, cv = separation(x_model, y_model, 5, 0.2), n_iter=32, verbose=2, n_jobs=-1)\n",
        "opt_XGB.fit(x_train01, y_model)\n",
        "\n",
        "n_estimators = opt_XGB.best_estimator_.n_estimators\n",
        "max_depth = opt_XGB.best_estimator_.max_depth\n",
        "subsample = opt_XGB.best_estimator_.subsample\n",
        "colsample_bytree = opt_XGB.best_estimator_.colsample_bytree\n",
        "\n",
        "print('n_estimators:', n_estimators,'max_depth:', max_depth, 'subsample:', subsample,'colsample_bytree:', colsample_bytree)"
      ],
      "metadata": {
        "id": "uWIlzb4dZYLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "#Creating a table to check accuracy on different DES classes\n",
        "XGB_df = x_model[:]\n",
        "XGB_df['Sugar'] = y_model\n",
        "\n",
        "for train_idx, val_idx in cv:\n",
        "    x_train_mod, x_test_mod = x_model.iloc[train_idx], x_model.iloc[val_idx]\n",
        "    y_train_mod, y_test_mod = y_model.iloc[train_idx], y_model.iloc[val_idx]\n",
        "\n",
        "    #Scaling the data\n",
        "    sc = MinMaxScaler(feature_range=(0, 1))\n",
        "    x_train_mod = sc.fit_transform(x_train_mod)\n",
        "    x_test_mod = sc.transform(x_test_mod)\n",
        "    #XGB\n",
        "    regr_XGB = XGBClassifier()\n",
        "    # regr_XGB = XGBClassifier(n_estimators = n_estimators, max_depth = max_depth, subsample = subsample, colsample_bytree = colsample_bytree)\n",
        "    regr_XGB.fit(x_train_mod, y_train_mod)\n",
        "    y_pred = regr_XGB.predict(x_test_mod)\n",
        "    y1_pred = regr_XGB.predict(x_train_mod)\n",
        "    #Filling in the table in accordance with the metrics\n",
        "    XGB_df['Sugar_train' + str(count)] = None\n",
        "    XGB_df['Sugar_test' + str(count)] = None\n",
        "    XGB_df['Sugar_train' + str(count)].iloc[train_idx] = y1_pred\n",
        "    XGB_df['Sugar_test' + str(count)].iloc[val_idx] = y_pred\n",
        "    #Calculating metrics\n",
        "    df_error_train['XGBoosting Regression' + str(count)] = metrics(regr_XGB, x_train_mod, y_train_mod, y_test_mod, y_pred, y1_pred)\n",
        "    count +=1\n",
        "df_error_train"
      ],
      "metadata": {
        "id": "Jtr4ezwlZgAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. General graphs"
      ],
      "metadata": {
        "id": "2fOax3iYZnc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#General table obtained after cross-validation\n",
        "df_error_train.index = ['F1_train', 'F1_test', 'Accuracy_train', 'Accuracy_test']\n",
        "df_error_train"
      ],
      "metadata": {
        "id": "prFp0WpEZogV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Table with averages and deviations for metrics\n",
        "df_error_train_1 = df_error_train.transpose()\n",
        "f_get_name = lambda x: x[:-1]\n",
        "df_error_train_1['Regr'] = df_error_train_1.index\n",
        "df_error_train_1['Regr'] = df_error_train_1['Regr'].apply(f_get_name)\n",
        "df_error_train_1 = df_error_train_1.groupby('Regr').agg(['mean', 'std'])\n",
        "df_error_train_1.columns = ['_'.join(col).rstrip('_') for col in df_error_train_1.columns.values] #Названия для новых столбцов\n",
        "df_error_train_1"
      ],
      "metadata": {
        "id": "6VZ_MekRZuCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.patches as mpatches\n",
        "#Let's build a graph that will help compare the methods by the main metrics\n",
        "\n",
        "barWidth = 0.4\n",
        "\n",
        "br1 = np.arange(3)\n",
        "br2 = [x + barWidth for x in br1]\n",
        "br3 =  np.arange(3)\n",
        "br4 = [x + barWidth for x in br3]\n",
        "\n",
        "fig, ((ax1, ax2)) = plt.subplots(nrows=1, ncols=2, sharex=True, figsize=(20, 6))\n",
        "\n",
        "ax1.bar(br1, df_error_train_1['F1_train_mean'], color =colors[0], width = barWidth, label ='F1_train', yerr = df_error_train_1['F1_train_std'])\n",
        "ax1.bar(br2, df_error_train_1['F1_test_mean'], color =colors[1], width = barWidth, label ='F1_validation', yerr = df_error_train_1['F1_test_std'])\n",
        "\n",
        "ax2.bar(br3, df_error_train_1['Accuracy_train_mean'], color =colors[4], width = barWidth, label ='Accuracy_train', yerr = df_error_train_1['Accuracy_train_std'])\n",
        "ax2.bar(br4, df_error_train_1['Accuracy_test_mean'], color =colors[3], width = barWidth, label ='Accuracy_validation', yerr = df_error_train_1['Accuracy_test_std'])\n",
        "\n",
        "plt.xticks(br1, ['GBR','RFR','XGB'], fontsize = 12)\n",
        "\n",
        "ax1.grid(color='#C3C6BA', linewidth=0.3)\n",
        "ax2.grid(color='#C3C6BA', linewidth=0.3)\n",
        "\n",
        "\n",
        "ax1.legend(fontsize = 12)\n",
        "ax2.legend(fontsize = 12)\n"
      ],
      "metadata": {
        "id": "MjadzZGoZvvr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}