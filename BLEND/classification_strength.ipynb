{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D_WNHUdWdSW"
      },
      "source": [
        "# Uploading files to collab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hR9YL8q0WxJ2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVR\n",
        "from skopt import BayesSearchCV\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from skopt.space import Integer, Real, Categorical\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "import shap\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import balanced_accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSF830oXW2u5"
      },
      "source": [
        "# ML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEUz6gyGXDm8"
      },
      "source": [
        "## 1. Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClbHv28CXNWu"
      },
      "source": [
        "### 1.1. Working with the table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9ZDEBTnvW--0"
      },
      "outputs": [],
      "source": [
        "db_2 = pd.read_excel('data_for_ML_unn_for_class.xlsx')\n",
        "db_1 = db_2.drop(columns=['Wine_strength'])\n",
        "db_1.insert(50, 'Wine_strength', db_2['Wine_strength'])\n",
        "db_final = db_1.drop(columns=['Sugar_encoded'])\n",
        "db_final.insert(0, 'Sugar_encoded', db_1['Sugar_encoded'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "M-zMyKArXXGN"
      },
      "outputs": [],
      "source": [
        "colors = ['#a5678e','#e8b7d4', '#beb7d9', '#7eabd4', '#31539d']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jrKEYAT9XX1W"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sugar_encoded</th>\n",
              "      <th>1_vec_1</th>\n",
              "      <th>1_vec_2</th>\n",
              "      <th>1_vec_3</th>\n",
              "      <th>1_vec_4</th>\n",
              "      <th>1_vec_5</th>\n",
              "      <th>1_vec_6</th>\n",
              "      <th>1_vec_7</th>\n",
              "      <th>1_vec_8</th>\n",
              "      <th>1_vec_9</th>\n",
              "      <th>...</th>\n",
              "      <th>4_vec_8</th>\n",
              "      <th>4_vec_9</th>\n",
              "      <th>4_vec_10</th>\n",
              "      <th>%_4</th>\n",
              "      <th>Harvest_year</th>\n",
              "      <th>Color_Orange</th>\n",
              "      <th>Color_Pink</th>\n",
              "      <th>Color_Red</th>\n",
              "      <th>Color_White</th>\n",
              "      <th>Wine_strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>14389.000000</td>\n",
              "      <td>14389.000000</td>\n",
              "      <td>14389.000000</td>\n",
              "      <td>14389.000000</td>\n",
              "      <td>14389.000000</td>\n",
              "      <td>14389.000000</td>\n",
              "      <td>14389.000000</td>\n",
              "      <td>14389.000000</td>\n",
              "      <td>14389.000000</td>\n",
              "      <td>14389.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>14389.000000</td>\n",
              "      <td>14389.000000</td>\n",
              "      <td>14389.000000</td>\n",
              "      <td>14389.000000</td>\n",
              "      <td>14389.000000</td>\n",
              "      <td>14389.000000</td>\n",
              "      <td>14389.000000</td>\n",
              "      <td>14389.000000</td>\n",
              "      <td>14389.00000</td>\n",
              "      <td>14389.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.167837</td>\n",
              "      <td>0.060454</td>\n",
              "      <td>0.018292</td>\n",
              "      <td>0.079030</td>\n",
              "      <td>0.038532</td>\n",
              "      <td>0.019369</td>\n",
              "      <td>0.091676</td>\n",
              "      <td>0.173179</td>\n",
              "      <td>0.058107</td>\n",
              "      <td>-0.077239</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005718</td>\n",
              "      <td>-0.003516</td>\n",
              "      <td>0.002559</td>\n",
              "      <td>0.002489</td>\n",
              "      <td>0.597499</td>\n",
              "      <td>0.003405</td>\n",
              "      <td>0.045521</td>\n",
              "      <td>0.551393</td>\n",
              "      <td>0.39968</td>\n",
              "      <td>2.548753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.700276</td>\n",
              "      <td>0.253451</td>\n",
              "      <td>0.277256</td>\n",
              "      <td>0.367961</td>\n",
              "      <td>0.269708</td>\n",
              "      <td>0.334826</td>\n",
              "      <td>0.312388</td>\n",
              "      <td>0.321148</td>\n",
              "      <td>0.300864</td>\n",
              "      <td>0.304123</td>\n",
              "      <td>...</td>\n",
              "      <td>0.061957</td>\n",
              "      <td>0.049046</td>\n",
              "      <td>0.060644</td>\n",
              "      <td>0.020515</td>\n",
              "      <td>0.442962</td>\n",
              "      <td>0.058258</td>\n",
              "      <td>0.208451</td>\n",
              "      <td>0.497369</td>\n",
              "      <td>0.48985</td>\n",
              "      <td>0.669392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.626064</td>\n",
              "      <td>-0.638262</td>\n",
              "      <td>-0.626405</td>\n",
              "      <td>-0.666614</td>\n",
              "      <td>-0.582963</td>\n",
              "      <td>-0.613744</td>\n",
              "      <td>-0.686419</td>\n",
              "      <td>-0.579507</td>\n",
              "      <td>-0.636982</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.579029</td>\n",
              "      <td>-0.636982</td>\n",
              "      <td>-0.553962</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.093300</td>\n",
              "      <td>-0.179822</td>\n",
              "      <td>-0.322336</td>\n",
              "      <td>-0.146991</td>\n",
              "      <td>-0.297306</td>\n",
              "      <td>-0.223522</td>\n",
              "      <td>-0.115570</td>\n",
              "      <td>-0.241545</td>\n",
              "      <td>-0.339760</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.096905</td>\n",
              "      <td>-0.037406</td>\n",
              "      <td>0.191290</td>\n",
              "      <td>-0.010493</td>\n",
              "      <td>0.071893</td>\n",
              "      <td>0.128300</td>\n",
              "      <td>0.310806</td>\n",
              "      <td>0.160546</td>\n",
              "      <td>-0.150012</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.887324</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.257025</td>\n",
              "      <td>0.285380</td>\n",
              "      <td>0.427216</td>\n",
              "      <td>0.150550</td>\n",
              "      <td>0.328234</td>\n",
              "      <td>0.405705</td>\n",
              "      <td>0.433208</td>\n",
              "      <td>0.276289</td>\n",
              "      <td>0.099057</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.957746</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.687540</td>\n",
              "      <td>0.629917</td>\n",
              "      <td>0.807477</td>\n",
              "      <td>0.717936</td>\n",
              "      <td>0.611457</td>\n",
              "      <td>0.630208</td>\n",
              "      <td>0.669380</td>\n",
              "      <td>0.683798</td>\n",
              "      <td>0.613503</td>\n",
              "      <td>...</td>\n",
              "      <td>0.502610</td>\n",
              "      <td>0.545916</td>\n",
              "      <td>0.516585</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 51 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Sugar_encoded       1_vec_1       1_vec_2       1_vec_3       1_vec_4  \\\n",
              "count   14389.000000  14389.000000  14389.000000  14389.000000  14389.000000   \n",
              "mean        1.167837      0.060454      0.018292      0.079030      0.038532   \n",
              "std         0.700276      0.253451      0.277256      0.367961      0.269708   \n",
              "min         0.000000     -0.626064     -0.638262     -0.626405     -0.666614   \n",
              "25%         1.000000     -0.093300     -0.179822     -0.322336     -0.146991   \n",
              "50%         1.000000      0.096905     -0.037406      0.191290     -0.010493   \n",
              "75%         1.000000      0.257025      0.285380      0.427216      0.150550   \n",
              "max         4.000000      0.687540      0.629917      0.807477      0.717936   \n",
              "\n",
              "            1_vec_5       1_vec_6       1_vec_7       1_vec_8       1_vec_9  \\\n",
              "count  14389.000000  14389.000000  14389.000000  14389.000000  14389.000000   \n",
              "mean       0.019369      0.091676      0.173179      0.058107     -0.077239   \n",
              "std        0.334826      0.312388      0.321148      0.300864      0.304123   \n",
              "min       -0.582963     -0.613744     -0.686419     -0.579507     -0.636982   \n",
              "25%       -0.297306     -0.223522     -0.115570     -0.241545     -0.339760   \n",
              "50%        0.071893      0.128300      0.310806      0.160546     -0.150012   \n",
              "75%        0.328234      0.405705      0.433208      0.276289      0.099057   \n",
              "max        0.611457      0.630208      0.669380      0.683798      0.613503   \n",
              "\n",
              "       ...       4_vec_8       4_vec_9      4_vec_10           %_4  \\\n",
              "count  ...  14389.000000  14389.000000  14389.000000  14389.000000   \n",
              "mean   ...      0.005718     -0.003516      0.002559      0.002489   \n",
              "std    ...      0.061957      0.049046      0.060644      0.020515   \n",
              "min    ...     -0.579029     -0.636982     -0.553962      0.000000   \n",
              "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
              "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
              "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
              "max    ...      0.502610      0.545916      0.516585      1.000000   \n",
              "\n",
              "       Harvest_year  Color_Orange    Color_Pink     Color_Red  Color_White  \\\n",
              "count  14389.000000  14389.000000  14389.000000  14389.000000  14389.00000   \n",
              "mean       0.597499      0.003405      0.045521      0.551393      0.39968   \n",
              "std        0.442962      0.058258      0.208451      0.497369      0.48985   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.00000   \n",
              "25%        0.000000      0.000000      0.000000      0.000000      0.00000   \n",
              "50%        0.887324      0.000000      0.000000      1.000000      0.00000   \n",
              "75%        0.957746      0.000000      0.000000      1.000000      1.00000   \n",
              "max        1.000000      1.000000      1.000000      1.000000      1.00000   \n",
              "\n",
              "       Wine_strength  \n",
              "count   14389.000000  \n",
              "mean        2.548753  \n",
              "std         0.669392  \n",
              "min         0.000000  \n",
              "25%         2.000000  \n",
              "50%         3.000000  \n",
              "75%         3.000000  \n",
              "max         4.000000  \n",
              "\n",
              "[8 rows x 51 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "db_final.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RUUYh0dXc_E"
      },
      "source": [
        "### 1.2. Splitting data into test and train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CWwXYmQ0XhAZ"
      },
      "outputs": [],
      "source": [
        "def separation(x,y,n_splits,test_size):\n",
        "    separation = []\n",
        "    k_fold = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=42)\n",
        "    for train_idx, test_idx in k_fold.split(x, y):\n",
        "        separation.append((train_idx, test_idx))\n",
        "    return separation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4uvKZyUqXjxN"
      },
      "outputs": [],
      "source": [
        "y = db_final.loc[:,'Wine_strength']\n",
        "x = db_final.loc[:,'1_vec_1':]\n",
        "cv = separation(x, y, 1, 0.2)\n",
        "for train_idx, val_idx in cv:\n",
        "    x_train, x_test = x.iloc[train_idx], x.iloc[val_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[val_idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiB_N6vEXl8E"
      },
      "source": [
        "### 1.3. Functions for plotting and calculating metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pcEBZSqvXpMH"
      },
      "outputs": [],
      "source": [
        "def metrics(regr, x_train, y_train, y_test, y_pred, y1_pred):\n",
        "    F1 = f1_score(y_test, y_pred, average='micro')\n",
        "    F1_train = f1_score(y_train, y1_pred, average='micro')\n",
        "    Accuracy = balanced_accuracy_score(y_test, y_pred)\n",
        "    Accuracy_train = balanced_accuracy_score(y_train, y1_pred)\n",
        "\n",
        "    print('f1_score:', F1)\n",
        "    print('Accuracy:', Accuracy)\n",
        "    print('f1_train:', F1_train)\n",
        "    print('Accuracy_train:', Accuracy_train)\n",
        "    return [F1_train, F1, Accuracy_train, Accuracy]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgYn-6KPXw8T"
      },
      "source": [
        "## 2. Random Forest Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PmRIyK-YX55y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=7, max_features=19, min_samples_leaf=0.07759017742813529, min_samples_split=0.30190391618466733, n_estimators=315; total time=   9.2s\n",
            "[CV] END criterion=entropy, max_depth=7, max_features=19, min_samples_leaf=0.07759017742813529, min_samples_split=0.30190391618466733, n_estimators=315; total time=   9.1s\n",
            "[CV] END criterion=entropy, max_depth=7, max_features=19, min_samples_leaf=0.07759017742813529, min_samples_split=0.30190391618466733, n_estimators=315; total time=   9.3s\n",
            "[CV] END criterion=entropy, max_depth=7, max_features=19, min_samples_leaf=0.07759017742813529, min_samples_split=0.30190391618466733, n_estimators=315; total time=   9.4s\n",
            "[CV] END criterion=entropy, max_depth=7, max_features=19, min_samples_leaf=0.07759017742813529, min_samples_split=0.30190391618466733, n_estimators=315; total time=   4.4s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=8, min_samples_leaf=0.06893273410521411, min_samples_split=0.2573979754121753, n_estimators=345; total time=   4.9s\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=8, min_samples_leaf=0.06893273410521411, min_samples_split=0.2573979754121753, n_estimators=345; total time=   5.0s\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=8, min_samples_leaf=0.06893273410521411, min_samples_split=0.2573979754121753, n_estimators=345; total time=   5.0s\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=8, min_samples_leaf=0.06893273410521411, min_samples_split=0.2573979754121753, n_estimators=345; total time=   5.1s\n",
            "[CV] END criterion=entropy, max_depth=5, max_features=8, min_samples_leaf=0.06893273410521411, min_samples_split=0.2573979754121753, n_estimators=345; total time=   3.2s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=8, max_features=22, min_samples_leaf=0.44313739741280694, min_samples_split=0.0659228404738668, n_estimators=291; total time=   2.6s\n",
            "[CV] END criterion=entropy, max_depth=8, max_features=22, min_samples_leaf=0.44313739741280694, min_samples_split=0.0659228404738668, n_estimators=291; total time=   2.6s\n",
            "[CV] END criterion=entropy, max_depth=8, max_features=22, min_samples_leaf=0.44313739741280694, min_samples_split=0.0659228404738668, n_estimators=291; total time=   2.6s\n",
            "[CV] END criterion=entropy, max_depth=8, max_features=22, min_samples_leaf=0.44313739741280694, min_samples_split=0.0659228404738668, n_estimators=291; total time=   2.6s\n",
            "[CV] END criterion=entropy, max_depth=8, max_features=22, min_samples_leaf=0.44313739741280694, min_samples_split=0.0659228404738668, n_estimators=291; total time=   1.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=4, max_features=18, min_samples_leaf=0.21228881241801634, min_samples_split=0.32991648873391466, n_estimators=377; total time=   6.3s\n",
            "[CV] END criterion=entropy, max_depth=4, max_features=18, min_samples_leaf=0.21228881241801634, min_samples_split=0.32991648873391466, n_estimators=377; total time=   6.3s\n",
            "[CV] END criterion=entropy, max_depth=4, max_features=18, min_samples_leaf=0.21228881241801634, min_samples_split=0.32991648873391466, n_estimators=377; total time=   6.3s\n",
            "[CV] END criterion=entropy, max_depth=4, max_features=18, min_samples_leaf=0.21228881241801634, min_samples_split=0.32991648873391466, n_estimators=377; total time=   6.3s\n",
            "[CV] END criterion=entropy, max_depth=4, max_features=18, min_samples_leaf=0.21228881241801634, min_samples_split=0.32991648873391466, n_estimators=377; total time=   3.5s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=2, max_features=4, min_samples_leaf=0.35287734270136173, min_samples_split=0.11767837541950633, n_estimators=236; total time=   2.9s\n",
            "[CV] END criterion=entropy, max_depth=2, max_features=4, min_samples_leaf=0.35287734270136173, min_samples_split=0.11767837541950633, n_estimators=236; total time=   2.9s\n",
            "[CV] END criterion=entropy, max_depth=2, max_features=4, min_samples_leaf=0.35287734270136173, min_samples_split=0.11767837541950633, n_estimators=236; total time=   2.9s\n",
            "[CV] END criterion=entropy, max_depth=2, max_features=4, min_samples_leaf=0.35287734270136173, min_samples_split=0.11767837541950633, n_estimators=236; total time=   3.0s\n",
            "[CV] END criterion=entropy, max_depth=2, max_features=4, min_samples_leaf=0.35287734270136173, min_samples_split=0.11767837541950633, n_estimators=236; total time=   1.2s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=2, max_features=12, min_samples_leaf=0.05515974745603343, min_samples_split=0.5459479912028423, n_estimators=354; total time=   5.7s\n",
            "[CV] END criterion=entropy, max_depth=2, max_features=12, min_samples_leaf=0.05515974745603343, min_samples_split=0.5459479912028423, n_estimators=354; total time=   5.6s\n",
            "[CV] END criterion=entropy, max_depth=2, max_features=12, min_samples_leaf=0.05515974745603343, min_samples_split=0.5459479912028423, n_estimators=354; total time=   5.6s\n",
            "[CV] END criterion=entropy, max_depth=2, max_features=12, min_samples_leaf=0.05515974745603343, min_samples_split=0.5459479912028423, n_estimators=354; total time=   5.6s\n",
            "[CV] END criterion=entropy, max_depth=2, max_features=12, min_samples_leaf=0.05515974745603343, min_samples_split=0.5459479912028423, n_estimators=354; total time=   2.9s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=9, min_samples_leaf=0.3712812775982701, min_samples_split=0.538824506283974, n_estimators=381; total time=   3.7s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=9, min_samples_leaf=0.3712812775982701, min_samples_split=0.538824506283974, n_estimators=381; total time=   3.8s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=9, min_samples_leaf=0.3712812775982701, min_samples_split=0.538824506283974, n_estimators=381; total time=   3.8s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=9, min_samples_leaf=0.3712812775982701, min_samples_split=0.538824506283974, n_estimators=381; total time=   3.9s\n",
            "[CV] END criterion=entropy, max_depth=6, max_features=9, min_samples_leaf=0.3712812775982701, min_samples_split=0.538824506283974, n_estimators=381; total time=   1.9s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=11, max_features=19, min_samples_leaf=0.25024342845967035, min_samples_split=0.1288191360394435, n_estimators=305; total time=   3.9s\n",
            "[CV] END criterion=entropy, max_depth=11, max_features=19, min_samples_leaf=0.25024342845967035, min_samples_split=0.1288191360394435, n_estimators=305; total time=   3.9s\n",
            "[CV] END criterion=entropy, max_depth=11, max_features=19, min_samples_leaf=0.25024342845967035, min_samples_split=0.1288191360394435, n_estimators=305; total time=   4.0s\n",
            "[CV] END criterion=entropy, max_depth=11, max_features=19, min_samples_leaf=0.25024342845967035, min_samples_split=0.1288191360394435, n_estimators=305; total time=   3.9s\n",
            "[CV] END criterion=entropy, max_depth=11, max_features=19, min_samples_leaf=0.25024342845967035, min_samples_split=0.1288191360394435, n_estimators=305; total time=   1.8s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=7, max_features=4, min_samples_leaf=0.4360420061845179, min_samples_split=0.22533778560974618, n_estimators=59; total time=   0.4s\n",
            "[CV] END criterion=entropy, max_depth=7, max_features=4, min_samples_leaf=0.4360420061845179, min_samples_split=0.22533778560974618, n_estimators=59; total time=   0.4s\n",
            "[CV] END criterion=entropy, max_depth=7, max_features=4, min_samples_leaf=0.4360420061845179, min_samples_split=0.22533778560974618, n_estimators=59; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=7, max_features=4, min_samples_leaf=0.4360420061845179, min_samples_split=0.22533778560974618, n_estimators=59; total time=   0.4s\n",
            "[CV] END criterion=entropy, max_depth=7, max_features=4, min_samples_leaf=0.4360420061845179, min_samples_split=0.22533778560974618, n_estimators=59; total time=   0.2s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=4, max_features=3, min_samples_leaf=0.17603292471767967, min_samples_split=0.5778738809875227, n_estimators=75; total time=   0.8s\n",
            "[CV] END criterion=entropy, max_depth=4, max_features=3, min_samples_leaf=0.17603292471767967, min_samples_split=0.5778738809875227, n_estimators=75; total time=   0.8s\n",
            "[CV] END criterion=entropy, max_depth=4, max_features=3, min_samples_leaf=0.17603292471767967, min_samples_split=0.5778738809875227, n_estimators=75; total time=   0.9s\n",
            "[CV] END criterion=entropy, max_depth=4, max_features=3, min_samples_leaf=0.17603292471767967, min_samples_split=0.5778738809875227, n_estimators=75; total time=   0.8s\n",
            "[CV] END criterion=entropy, max_depth=4, max_features=3, min_samples_leaf=0.17603292471767967, min_samples_split=0.5778738809875227, n_estimators=75; total time=   0.4s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=24, min_samples_leaf=0.01, min_samples_split=0.5726172639036405, n_estimators=95; total time=   2.1s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=24, min_samples_leaf=0.01, min_samples_split=0.5726172639036405, n_estimators=95; total time=   2.1s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=24, min_samples_leaf=0.01, min_samples_split=0.5726172639036405, n_estimators=95; total time=   2.2s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=24, min_samples_leaf=0.01, min_samples_split=0.5726172639036405, n_estimators=95; total time=   2.1s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=24, min_samples_leaf=0.01, min_samples_split=0.5726172639036405, n_estimators=95; total time=   0.9s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=24, min_samples_leaf=0.2330538705169692, min_samples_split=0.6, n_estimators=340; total time=   5.2s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=24, min_samples_leaf=0.2330538705169692, min_samples_split=0.6, n_estimators=340; total time=   5.2s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=24, min_samples_leaf=0.2330538705169692, min_samples_split=0.6, n_estimators=340; total time=   5.3s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=24, min_samples_leaf=0.2330538705169692, min_samples_split=0.6, n_estimators=340; total time=   5.3s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=24, min_samples_leaf=0.2330538705169692, min_samples_split=0.6, n_estimators=340; total time=   2.6s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=22, min_samples_leaf=0.10919262324738611, min_samples_split=0.01, n_estimators=52; total time=   2.6s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=22, min_samples_leaf=0.10919262324738611, min_samples_split=0.01, n_estimators=52; total time=   2.5s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=22, min_samples_leaf=0.10919262324738611, min_samples_split=0.01, n_estimators=52; total time=   2.6s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=22, min_samples_leaf=0.10919262324738611, min_samples_split=0.01, n_estimators=52; total time=   2.6s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=22, min_samples_leaf=0.10919262324738611, min_samples_split=0.01, n_estimators=52; total time=   0.8s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=7, max_features=24, min_samples_leaf=0.2298936103209697, min_samples_split=0.01, n_estimators=400; total time=   8.4s\n",
            "[CV] END criterion=entropy, max_depth=7, max_features=24, min_samples_leaf=0.2298936103209697, min_samples_split=0.01, n_estimators=400; total time=   8.4s\n",
            "[CV] END criterion=entropy, max_depth=7, max_features=24, min_samples_leaf=0.2298936103209697, min_samples_split=0.01, n_estimators=400; total time=   8.4s\n",
            "[CV] END criterion=entropy, max_depth=7, max_features=24, min_samples_leaf=0.2298936103209697, min_samples_split=0.01, n_estimators=400; total time=   8.5s\n",
            "[CV] END criterion=entropy, max_depth=7, max_features=24, min_samples_leaf=0.2298936103209697, min_samples_split=0.01, n_estimators=400; total time=   4.5s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=1, max_features=3, min_samples_leaf=0.2370442030383327, min_samples_split=0.01, n_estimators=50; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=1, max_features=3, min_samples_leaf=0.2370442030383327, min_samples_split=0.01, n_estimators=50; total time=   0.6s\n",
            "[CV] END criterion=entropy, max_depth=1, max_features=3, min_samples_leaf=0.2370442030383327, min_samples_split=0.01, n_estimators=50; total time=   0.6s\n",
            "[CV] END criterion=entropy, max_depth=1, max_features=3, min_samples_leaf=0.2370442030383327, min_samples_split=0.01, n_estimators=50; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=1, max_features=3, min_samples_leaf=0.2370442030383327, min_samples_split=0.01, n_estimators=50; total time=   0.3s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=3, min_samples_leaf=0.01, min_samples_split=0.01, n_estimators=50; total time=   0.6s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=3, min_samples_leaf=0.01, min_samples_split=0.01, n_estimators=50; total time=   0.6s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=3, min_samples_leaf=0.01, min_samples_split=0.01, n_estimators=50; total time=   0.6s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=3, min_samples_leaf=0.01, min_samples_split=0.01, n_estimators=50; total time=   0.6s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=3, min_samples_leaf=0.01, min_samples_split=0.01, n_estimators=50; total time=   0.3s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=3, min_samples_leaf=0.056860551326778905, min_samples_split=0.01, n_estimators=50; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=3, min_samples_leaf=0.056860551326778905, min_samples_split=0.01, n_estimators=50; total time=   0.6s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=3, min_samples_leaf=0.056860551326778905, min_samples_split=0.01, n_estimators=50; total time=   0.6s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=3, min_samples_leaf=0.056860551326778905, min_samples_split=0.01, n_estimators=50; total time=   0.6s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=3, min_samples_leaf=0.056860551326778905, min_samples_split=0.01, n_estimators=50; total time=   0.3s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=24, min_samples_leaf=0.12916046941922374, min_samples_split=0.01, n_estimators=400; total time=   8.3s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=24, min_samples_leaf=0.12916046941922374, min_samples_split=0.01, n_estimators=400; total time=   8.5s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=24, min_samples_leaf=0.12916046941922374, min_samples_split=0.01, n_estimators=400; total time=   8.5s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=24, min_samples_leaf=0.12916046941922374, min_samples_split=0.01, n_estimators=400; total time=   8.6s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=24, min_samples_leaf=0.12916046941922374, min_samples_split=0.01, n_estimators=400; total time=   4.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=12, min_samples_leaf=0.01, min_samples_split=0.01, n_estimators=400; total time=  12.7s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=12, min_samples_leaf=0.01, min_samples_split=0.01, n_estimators=400; total time=  12.7s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=12, min_samples_leaf=0.01, min_samples_split=0.01, n_estimators=400; total time=  12.8s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=12, min_samples_leaf=0.01, min_samples_split=0.01, n_estimators=400; total time=  12.8s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=12, min_samples_leaf=0.01, min_samples_split=0.01, n_estimators=400; total time=   6.3s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=1, max_features=24, min_samples_leaf=0.2817529987555709, min_samples_split=0.01, n_estimators=400; total time=   7.4s\n",
            "[CV] END criterion=entropy, max_depth=1, max_features=24, min_samples_leaf=0.2817529987555709, min_samples_split=0.01, n_estimators=400; total time=   7.5s\n",
            "[CV] END criterion=entropy, max_depth=1, max_features=24, min_samples_leaf=0.2817529987555709, min_samples_split=0.01, n_estimators=400; total time=   7.5s\n",
            "[CV] END criterion=entropy, max_depth=1, max_features=24, min_samples_leaf=0.2817529987555709, min_samples_split=0.01, n_estimators=400; total time=   7.6s\n",
            "[CV] END criterion=entropy, max_depth=1, max_features=24, min_samples_leaf=0.2817529987555709, min_samples_split=0.01, n_estimators=400; total time=   3.5s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=4, max_features=24, min_samples_leaf=0.17876081420378898, min_samples_split=0.12552437094018298, n_estimators=58; total time=   0.8s\n",
            "[CV] END criterion=entropy, max_depth=4, max_features=24, min_samples_leaf=0.17876081420378898, min_samples_split=0.12552437094018298, n_estimators=58; total time=   0.8s\n",
            "[CV] END criterion=entropy, max_depth=4, max_features=24, min_samples_leaf=0.17876081420378898, min_samples_split=0.12552437094018298, n_estimators=58; total time=   0.8s\n",
            "[CV] END criterion=entropy, max_depth=4, max_features=24, min_samples_leaf=0.17876081420378898, min_samples_split=0.12552437094018298, n_estimators=58; total time=   0.8s\n",
            "[CV] END criterion=entropy, max_depth=4, max_features=24, min_samples_leaf=0.17876081420378898, min_samples_split=0.12552437094018298, n_estimators=58; total time=   0.5s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=1, max_features=11, min_samples_leaf=0.01, min_samples_split=0.6, n_estimators=50; total time=   0.5s\n",
            "[CV] END criterion=entropy, max_depth=1, max_features=11, min_samples_leaf=0.01, min_samples_split=0.6, n_estimators=50; total time=   0.6s\n",
            "[CV] END criterion=entropy, max_depth=1, max_features=11, min_samples_leaf=0.01, min_samples_split=0.6, n_estimators=50; total time=   0.7s\n",
            "[CV] END criterion=entropy, max_depth=1, max_features=11, min_samples_leaf=0.01, min_samples_split=0.6, n_estimators=50; total time=   0.7s\n",
            "[CV] END criterion=entropy, max_depth=1, max_features=11, min_samples_leaf=0.01, min_samples_split=0.6, n_estimators=50; total time=   0.4s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=15, min_samples_leaf=0.03399516470198768, min_samples_split=0.01, n_estimators=50; total time=   2.2s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=15, min_samples_leaf=0.03399516470198768, min_samples_split=0.01, n_estimators=50; total time=   2.2s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=15, min_samples_leaf=0.03399516470198768, min_samples_split=0.01, n_estimators=50; total time=   2.3s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=15, min_samples_leaf=0.03399516470198768, min_samples_split=0.01, n_estimators=50; total time=   2.2s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=15, min_samples_leaf=0.03399516470198768, min_samples_split=0.01, n_estimators=50; total time=   0.6s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=24, min_samples_leaf=0.04825779044752187, min_samples_split=0.01, n_estimators=400; total time=  13.7s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=24, min_samples_leaf=0.04825779044752187, min_samples_split=0.01, n_estimators=400; total time=  13.8s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=24, min_samples_leaf=0.04825779044752187, min_samples_split=0.01, n_estimators=400; total time=  13.8s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=24, min_samples_leaf=0.04825779044752187, min_samples_split=0.01, n_estimators=400; total time=  13.8s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=24, min_samples_leaf=0.04825779044752187, min_samples_split=0.01, n_estimators=400; total time=   5.6s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=3, min_samples_leaf=0.01, min_samples_split=0.6, n_estimators=400; total time=   4.4s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=3, min_samples_leaf=0.01, min_samples_split=0.6, n_estimators=400; total time=   4.5s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=3, min_samples_leaf=0.01, min_samples_split=0.6, n_estimators=400; total time=   4.5s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=3, min_samples_leaf=0.01, min_samples_split=0.6, n_estimators=400; total time=   4.5s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=3, min_samples_leaf=0.01, min_samples_split=0.6, n_estimators=400; total time=   1.8s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=1, max_features=24, min_samples_leaf=0.01, min_samples_split=0.01, n_estimators=400; total time=   7.1s\n",
            "[CV] END criterion=entropy, max_depth=1, max_features=24, min_samples_leaf=0.01, min_samples_split=0.01, n_estimators=400; total time=   7.2s\n",
            "[CV] END criterion=entropy, max_depth=1, max_features=24, min_samples_leaf=0.01, min_samples_split=0.01, n_estimators=400; total time=   7.2s\n",
            "[CV] END criterion=entropy, max_depth=1, max_features=24, min_samples_leaf=0.01, min_samples_split=0.01, n_estimators=400; total time=   7.2s\n",
            "[CV] END criterion=entropy, max_depth=1, max_features=24, min_samples_leaf=0.01, min_samples_split=0.01, n_estimators=400; total time=   2.8s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=24, min_samples_leaf=0.12075249156184288, min_samples_split=0.6, n_estimators=371; total time=   4.7s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=24, min_samples_leaf=0.12075249156184288, min_samples_split=0.6, n_estimators=371; total time=   4.8s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=24, min_samples_leaf=0.12075249156184288, min_samples_split=0.6, n_estimators=371; total time=   4.8s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=24, min_samples_leaf=0.12075249156184288, min_samples_split=0.6, n_estimators=371; total time=   4.8s\n",
            "[CV] END criterion=entropy, max_depth=10, max_features=24, min_samples_leaf=0.12075249156184288, min_samples_split=0.6, n_estimators=371; total time=   2.3s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=24, min_samples_leaf=0.061949958159068834, min_samples_split=0.6, n_estimators=400; total time=   5.2s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=24, min_samples_leaf=0.061949958159068834, min_samples_split=0.6, n_estimators=400; total time=   5.3s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=24, min_samples_leaf=0.061949958159068834, min_samples_split=0.6, n_estimators=400; total time=   5.3s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=24, min_samples_leaf=0.061949958159068834, min_samples_split=0.6, n_estimators=400; total time=   5.3s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=24, min_samples_leaf=0.061949958159068834, min_samples_split=0.6, n_estimators=400; total time=   2.5s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=7, max_features=12, min_samples_leaf=0.1325899155061371, min_samples_split=0.02925515190471023, n_estimators=154; total time=   2.2s\n",
            "[CV] END criterion=entropy, max_depth=7, max_features=12, min_samples_leaf=0.1325899155061371, min_samples_split=0.02925515190471023, n_estimators=154; total time=   2.2s\n",
            "[CV] END criterion=entropy, max_depth=7, max_features=12, min_samples_leaf=0.1325899155061371, min_samples_split=0.02925515190471023, n_estimators=154; total time=   2.2s\n",
            "[CV] END criterion=entropy, max_depth=7, max_features=12, min_samples_leaf=0.1325899155061371, min_samples_split=0.02925515190471023, n_estimators=154; total time=   2.2s\n",
            "[CV] END criterion=entropy, max_depth=7, max_features=12, min_samples_leaf=0.1325899155061371, min_samples_split=0.02925515190471023, n_estimators=154; total time=   1.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=24, min_samples_leaf=0.2679407342795079, min_samples_split=0.6, n_estimators=175; total time=   3.7s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=24, min_samples_leaf=0.2679407342795079, min_samples_split=0.6, n_estimators=175; total time=   3.7s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=24, min_samples_leaf=0.2679407342795079, min_samples_split=0.6, n_estimators=175; total time=   3.7s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=24, min_samples_leaf=0.2679407342795079, min_samples_split=0.6, n_estimators=175; total time=   3.7s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=24, min_samples_leaf=0.2679407342795079, min_samples_split=0.6, n_estimators=175; total time=   1.6s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=19, min_samples_leaf=0.15403716031992043, min_samples_split=0.5892913928263481, n_estimators=336; total time=   4.3s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=19, min_samples_leaf=0.15403716031992043, min_samples_split=0.5892913928263481, n_estimators=336; total time=   4.4s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=19, min_samples_leaf=0.15403716031992043, min_samples_split=0.5892913928263481, n_estimators=336; total time=   4.3s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=19, min_samples_leaf=0.15403716031992043, min_samples_split=0.5892913928263481, n_estimators=336; total time=   4.4s\n",
            "[CV] END criterion=entropy, max_depth=3, max_features=19, min_samples_leaf=0.15403716031992043, min_samples_split=0.5892913928263481, n_estimators=336; total time=   2.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=11, min_samples_leaf=0.01, min_samples_split=0.01, n_estimators=400; total time=  10.8s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=11, min_samples_leaf=0.01, min_samples_split=0.01, n_estimators=400; total time=  10.9s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=11, min_samples_leaf=0.01, min_samples_split=0.01, n_estimators=400; total time=  11.0s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=11, min_samples_leaf=0.01, min_samples_split=0.01, n_estimators=400; total time=  11.1s\n",
            "[CV] END criterion=entropy, max_depth=12, max_features=11, min_samples_leaf=0.01, min_samples_split=0.01, n_estimators=400; total time=   5.6s\n",
            "n_esti: 400 depth: 12 criterion: entropy min_leaf: 0.01 min_split: 0.01 max_feat: 11\n"
          ]
        }
      ],
      "source": [
        "class_RFC = RandomForestClassifier()\n",
        "\n",
        "search_space = {\"n_estimators\": Integer(50,400),\n",
        "    \"criterion\": Categorical(['entropy']),\n",
        "    \"min_samples_split\": Real(0.01, 0.6),\n",
        "    \"min_samples_leaf\": Real(0.01, 0.5),\n",
        "    \"max_depth\": Integer(1, 12),\n",
        "    \"max_features\": Integer(3, 24)}\n",
        "\n",
        "df_error_train = pd.DataFrame()\n",
        "x_model = x_train.copy().drop(['Wine_strength'],axis=1)\n",
        "\n",
        "y_model = y_train.copy()\n",
        "cv = separation(x_model, y_model, 5, 0.2)\n",
        "count = 0\n",
        "\n",
        "sc = MinMaxScaler(feature_range=(0, 1))\n",
        "x_train01 = sc.fit_transform(x_model)\n",
        "opt_RFC = BayesSearchCV(estimator = class_RFC, search_spaces=search_space, cv = separation(x_model, y_model, 5, 0.2), n_iter=32, verbose=2, n_jobs=-1)\n",
        "opt_RFC.fit(x_train01, y_model)\n",
        "\n",
        "n_esti = opt_RFC.best_estimator_.n_estimators\n",
        "criterion = opt_RFC.best_estimator_.criterion\n",
        "min_leaf = opt_RFC.best_estimator_.min_samples_leaf\n",
        "min_split = opt_RFC.best_estimator_.min_samples_split\n",
        "depth = opt_RFC.best_estimator_.max_depth\n",
        "max_feat = opt_RFC.best_estimator_.max_features\n",
        "\n",
        "print('n_esti:', n_esti,'depth:', depth, 'criterion:', criterion, 'min_leaf:', min_leaf,'min_split:', min_split,'max_feat:', max_feat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "U7Wqx1yjYDXU"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_score: 0.6691272253582284\n",
            "Accuracy: 0.2917091368001391\n",
            "f1_train: 0.6734361424847958\n",
            "Accuracy_train: 0.2947022347949081\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_score: 0.6621797655232305\n",
            "Accuracy: 0.2895304815291141\n",
            "f1_train: 0.6740877497827976\n",
            "Accuracy_train: 0.29488499903927845\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_score: 0.6695614415979158\n",
            "Accuracy: 0.2917014759120022\n",
            "f1_train: 0.6678974804517811\n",
            "Accuracy_train: 0.2931804363230414\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_score: 0.6508901432913591\n",
            "Accuracy: 0.28499061506580303\n",
            "f1_train: 0.6718071242397915\n",
            "Accuracy_train: 0.29381155566474704\n",
            "f1_score: 0.6634824142422927\n",
            "Accuracy: 0.29034421888790823\n",
            "f1_train: 0.6671372719374457\n",
            "Accuracy_train: 0.2924841370156795\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Random Forest Classification0</th>\n",
              "      <th>Random Forest Classification1</th>\n",
              "      <th>Random Forest Classification2</th>\n",
              "      <th>Random Forest Classification3</th>\n",
              "      <th>Random Forest Classification4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.673436</td>\n",
              "      <td>0.674088</td>\n",
              "      <td>0.667897</td>\n",
              "      <td>0.671807</td>\n",
              "      <td>0.667137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.669127</td>\n",
              "      <td>0.662180</td>\n",
              "      <td>0.669561</td>\n",
              "      <td>0.650890</td>\n",
              "      <td>0.663482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.294702</td>\n",
              "      <td>0.294885</td>\n",
              "      <td>0.293180</td>\n",
              "      <td>0.293812</td>\n",
              "      <td>0.292484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.291709</td>\n",
              "      <td>0.289530</td>\n",
              "      <td>0.291701</td>\n",
              "      <td>0.284991</td>\n",
              "      <td>0.290344</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Random Forest Classification0  Random Forest Classification1  \\\n",
              "0                       0.673436                       0.674088   \n",
              "1                       0.669127                       0.662180   \n",
              "2                       0.294702                       0.294885   \n",
              "3                       0.291709                       0.289530   \n",
              "\n",
              "   Random Forest Classification2  Random Forest Classification3  \\\n",
              "0                       0.667897                       0.671807   \n",
              "1                       0.669561                       0.650890   \n",
              "2                       0.293180                       0.293812   \n",
              "3                       0.291701                       0.284991   \n",
              "\n",
              "   Random Forest Classification4  \n",
              "0                       0.667137  \n",
              "1                       0.663482  \n",
              "2                       0.292484  \n",
              "3                       0.290344  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count = 0\n",
        "\n",
        "RFC_df = x_model[:]\n",
        "RFC_df['Strength'] = y_model\n",
        "\n",
        "for train_idx, val_idx in cv:\n",
        "    x_train_mod, x_test_mod = x_model.iloc[train_idx], x_model.iloc[val_idx]\n",
        "    y_train_mod, y_test_mod = y_model.iloc[train_idx], y_model.iloc[val_idx]\n",
        "\n",
        "    sc = MinMaxScaler(feature_range=(0, 1))\n",
        "    x_train_mod = sc.fit_transform(x_train_mod)\n",
        "    x_test_mod = sc.transform(x_test_mod)\n",
        "\n",
        "    regr_RFC = RandomForestClassifier(n_estimators=n_esti, max_depth=depth, min_samples_leaf=min_leaf,\n",
        "                                 min_samples_split=min_split, criterion=criterion, max_features=max_feat)\n",
        "    regr_RFC.fit(x_train_mod, y_train_mod)\n",
        "    y_pred = regr_RFC.predict(x_test_mod)\n",
        "    y1_pred = regr_RFC.predict(x_train_mod)\n",
        "\n",
        "    RFC_df['Strength_train' + str(count)] = None\n",
        "    RFC_df['Strength_test' + str(count)] = None\n",
        "    RFC_df['Strength_train' + str(count)].iloc[train_idx] = y1_pred\n",
        "    RFC_df['Strength_test' + str(count)].iloc[val_idx] = y_pred\n",
        "\n",
        "    df_error_train['Random Forest Classification' + str(count)] = metrics(regr_RFC, x_train_mod, y_train_mod, y_test_mod, y_pred, y1_pred)\n",
        "    count +=1\n",
        "df_error_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlMEsSGmYWEy"
      },
      "source": [
        "## 3. Gradient Boosting Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "heBmRc6QYf1X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.13831266527911606, max_depth=5, min_samples_leaf=0.4704450133554539, min_samples_split=0.5696657854364918, n_estimators=58; total time=  11.7s\n",
            "[CV] END learning_rate=0.13831266527911606, max_depth=5, min_samples_leaf=0.4704450133554539, min_samples_split=0.5696657854364918, n_estimators=58; total time=  11.7s\n",
            "[CV] END learning_rate=0.13831266527911606, max_depth=5, min_samples_leaf=0.4704450133554539, min_samples_split=0.5696657854364918, n_estimators=58; total time=  11.8s\n",
            "[CV] END learning_rate=0.13831266527911606, max_depth=5, min_samples_leaf=0.4704450133554539, min_samples_split=0.5696657854364918, n_estimators=58; total time=  12.0s\n",
            "[CV] END learning_rate=0.13831266527911606, max_depth=5, min_samples_leaf=0.4704450133554539, min_samples_split=0.5696657854364918, n_estimators=58; total time=   4.9s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.0768746957126654, max_depth=2, min_samples_leaf=0.22678222020706384, min_samples_split=0.5614307282626796, n_estimators=124; total time=  33.1s\n",
            "[CV] END learning_rate=0.0768746957126654, max_depth=2, min_samples_leaf=0.22678222020706384, min_samples_split=0.5614307282626796, n_estimators=124; total time=  33.3s\n",
            "[CV] END learning_rate=0.0768746957126654, max_depth=2, min_samples_leaf=0.22678222020706384, min_samples_split=0.5614307282626796, n_estimators=124; total time=  33.4s\n",
            "[CV] END learning_rate=0.0768746957126654, max_depth=2, min_samples_leaf=0.22678222020706384, min_samples_split=0.5614307282626796, n_estimators=124; total time=  33.7s\n",
            "[CV] END learning_rate=0.0768746957126654, max_depth=2, min_samples_leaf=0.22678222020706384, min_samples_split=0.5614307282626796, n_estimators=124; total time=  12.9s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.1340565482319594, max_depth=4, min_samples_leaf=0.14814678644304607, min_samples_split=0.326253968327214, n_estimators=54; total time=  20.9s\n",
            "[CV] END learning_rate=0.1340565482319594, max_depth=4, min_samples_leaf=0.14814678644304607, min_samples_split=0.326253968327214, n_estimators=54; total time=  20.9s\n",
            "[CV] END learning_rate=0.1340565482319594, max_depth=4, min_samples_leaf=0.14814678644304607, min_samples_split=0.326253968327214, n_estimators=54; total time=  21.0s\n",
            "[CV] END learning_rate=0.1340565482319594, max_depth=4, min_samples_leaf=0.14814678644304607, min_samples_split=0.326253968327214, n_estimators=54; total time=  21.1s\n",
            "[CV] END learning_rate=0.1340565482319594, max_depth=4, min_samples_leaf=0.14814678644304607, min_samples_split=0.326253968327214, n_estimators=54; total time=  11.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.10395981044683221, max_depth=6, min_samples_leaf=0.22290929810852478, min_samples_split=0.3702647434701987, n_estimators=146; total time=  43.6s\n",
            "[CV] END learning_rate=0.10395981044683221, max_depth=6, min_samples_leaf=0.22290929810852478, min_samples_split=0.3702647434701987, n_estimators=146; total time=  43.9s\n",
            "[CV] END learning_rate=0.10395981044683221, max_depth=6, min_samples_leaf=0.22290929810852478, min_samples_split=0.3702647434701987, n_estimators=146; total time=  44.1s\n",
            "[CV] END learning_rate=0.10395981044683221, max_depth=6, min_samples_leaf=0.22290929810852478, min_samples_split=0.3702647434701987, n_estimators=146; total time=  44.2s\n",
            "[CV] END learning_rate=0.10395981044683221, max_depth=6, min_samples_leaf=0.22290929810852478, min_samples_split=0.3702647434701987, n_estimators=146; total time=  16.7s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.1252498463946335, max_depth=3, min_samples_leaf=0.413302043998777, min_samples_split=0.03820139477505788, n_estimators=141; total time=  28.1s\n",
            "[CV] END learning_rate=0.1252498463946335, max_depth=3, min_samples_leaf=0.413302043998777, min_samples_split=0.03820139477505788, n_estimators=141; total time=  28.2s\n",
            "[CV] END learning_rate=0.1252498463946335, max_depth=3, min_samples_leaf=0.413302043998777, min_samples_split=0.03820139477505788, n_estimators=141; total time=  28.4s\n",
            "[CV] END learning_rate=0.1252498463946335, max_depth=3, min_samples_leaf=0.413302043998777, min_samples_split=0.03820139477505788, n_estimators=141; total time=  28.3s\n",
            "[CV] END learning_rate=0.1252498463946335, max_depth=3, min_samples_leaf=0.413302043998777, min_samples_split=0.03820139477505788, n_estimators=141; total time=  10.7s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.13928242960208023, max_depth=4, min_samples_leaf=0.3731765959230191, min_samples_split=0.11605233859249904, n_estimators=93; total time=  17.2s\n",
            "[CV] END learning_rate=0.13928242960208023, max_depth=4, min_samples_leaf=0.3731765959230191, min_samples_split=0.11605233859249904, n_estimators=93; total time=  17.3s\n",
            "[CV] END learning_rate=0.13928242960208023, max_depth=4, min_samples_leaf=0.3731765959230191, min_samples_split=0.11605233859249904, n_estimators=93; total time=  17.4s\n",
            "[CV] END learning_rate=0.13928242960208023, max_depth=4, min_samples_leaf=0.3731765959230191, min_samples_split=0.11605233859249904, n_estimators=93; total time=  17.4s\n",
            "[CV] END learning_rate=0.13928242960208023, max_depth=4, min_samples_leaf=0.3731765959230191, min_samples_split=0.11605233859249904, n_estimators=93; total time=   7.2s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.12843160368365802, max_depth=5, min_samples_leaf=0.3195228594227853, min_samples_split=0.3309074084661924, n_estimators=111; total time=  24.0s\n",
            "[CV] END learning_rate=0.12843160368365802, max_depth=5, min_samples_leaf=0.3195228594227853, min_samples_split=0.3309074084661924, n_estimators=111; total time=  24.1s\n",
            "[CV] END learning_rate=0.12843160368365802, max_depth=5, min_samples_leaf=0.3195228594227853, min_samples_split=0.3309074084661924, n_estimators=111; total time=  24.2s\n",
            "[CV] END learning_rate=0.12843160368365802, max_depth=5, min_samples_leaf=0.3195228594227853, min_samples_split=0.3309074084661924, n_estimators=111; total time=  24.2s\n",
            "[CV] END learning_rate=0.12843160368365802, max_depth=5, min_samples_leaf=0.3195228594227853, min_samples_split=0.3309074084661924, n_estimators=111; total time=   9.9s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.102277931175316, max_depth=4, min_samples_leaf=0.2556569073001465, min_samples_split=0.0758588366734334, n_estimators=96; total time=  26.2s\n",
            "[CV] END learning_rate=0.102277931175316, max_depth=4, min_samples_leaf=0.2556569073001465, min_samples_split=0.0758588366734334, n_estimators=96; total time=  26.5s\n",
            "[CV] END learning_rate=0.102277931175316, max_depth=4, min_samples_leaf=0.2556569073001465, min_samples_split=0.0758588366734334, n_estimators=96; total time=  26.7s\n",
            "[CV] END learning_rate=0.102277931175316, max_depth=4, min_samples_leaf=0.2556569073001465, min_samples_split=0.0758588366734334, n_estimators=96; total time=  26.7s\n",
            "[CV] END learning_rate=0.102277931175316, max_depth=4, min_samples_leaf=0.2556569073001465, min_samples_split=0.0758588366734334, n_estimators=96; total time=  10.2s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.05621084540818, max_depth=1, min_samples_leaf=0.06589278209111527, min_samples_split=0.5487984414638942, n_estimators=283; total time= 1.1min\n",
            "[CV] END learning_rate=0.05621084540818, max_depth=1, min_samples_leaf=0.06589278209111527, min_samples_split=0.5487984414638942, n_estimators=283; total time= 1.1min\n",
            "[CV] END learning_rate=0.05621084540818, max_depth=1, min_samples_leaf=0.06589278209111527, min_samples_split=0.5487984414638942, n_estimators=283; total time= 1.1min\n",
            "[CV] END learning_rate=0.05621084540818, max_depth=1, min_samples_leaf=0.06589278209111527, min_samples_split=0.5487984414638942, n_estimators=283; total time= 1.1min\n",
            "[CV] END learning_rate=0.05621084540818, max_depth=1, min_samples_leaf=0.06589278209111527, min_samples_split=0.5487984414638942, n_estimators=283; total time=  23.8s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.12816621765220987, max_depth=4, min_samples_leaf=0.41391577161531407, min_samples_split=0.24587885855632535, n_estimators=285; total time=  56.5s\n",
            "[CV] END learning_rate=0.12816621765220987, max_depth=4, min_samples_leaf=0.41391577161531407, min_samples_split=0.24587885855632535, n_estimators=285; total time=  56.6s\n",
            "[CV] END learning_rate=0.12816621765220987, max_depth=4, min_samples_leaf=0.41391577161531407, min_samples_split=0.24587885855632535, n_estimators=285; total time=  56.7s\n",
            "[CV] END learning_rate=0.12816621765220987, max_depth=4, min_samples_leaf=0.41391577161531407, min_samples_split=0.24587885855632535, n_estimators=285; total time=  56.8s\n",
            "[CV] END learning_rate=0.12816621765220987, max_depth=4, min_samples_leaf=0.41391577161531407, min_samples_split=0.24587885855632535, n_estimators=285; total time=  20.4s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.13207844458605575, max_depth=2, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=400; total time= 2.3min\n",
            "[CV] END learning_rate=0.13207844458605575, max_depth=2, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=400; total time= 2.3min\n",
            "[CV] END learning_rate=0.13207844458605575, max_depth=2, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=400; total time= 2.3min\n",
            "[CV] END learning_rate=0.13207844458605575, max_depth=2, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=400; total time= 2.3min\n",
            "[CV] END learning_rate=0.13207844458605575, max_depth=2, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=400; total time=  49.8s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.07853295918769236, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=50; total time=  31.0s\n",
            "[CV] END learning_rate=0.07853295918769236, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=50; total time=  31.6s\n",
            "[CV] END learning_rate=0.07853295918769236, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=50; total time=  31.6s\n",
            "[CV] END learning_rate=0.07853295918769236, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=50; total time=  31.7s\n",
            "[CV] END learning_rate=0.07853295918769236, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=50; total time=  16.3s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_samples_leaf=0.05, min_samples_split=0.1794436129756517, n_estimators=400; total time= 1.4min\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_samples_leaf=0.05, min_samples_split=0.1794436129756517, n_estimators=400; total time= 1.4min\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_samples_leaf=0.05, min_samples_split=0.1794436129756517, n_estimators=400; total time= 1.4min\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_samples_leaf=0.05, min_samples_split=0.1794436129756517, n_estimators=400; total time= 1.4min\n",
            "[CV] END learning_rate=0.05, max_depth=1, min_samples_leaf=0.05, min_samples_split=0.1794436129756517, n_estimators=400; total time=  32.3s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=50; total time=  32.5s\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=50; total time=  32.8s\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=50; total time=  32.9s\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=50; total time=  33.0s\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=50; total time=  13.9s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.15, max_depth=5, min_samples_leaf=0.10974874538564039, min_samples_split=0.02, n_estimators=400; total time= 3.3min\n",
            "[CV] END learning_rate=0.15, max_depth=5, min_samples_leaf=0.10974874538564039, min_samples_split=0.02, n_estimators=400; total time= 3.3min\n",
            "[CV] END learning_rate=0.15, max_depth=5, min_samples_leaf=0.10974874538564039, min_samples_split=0.02, n_estimators=400; total time= 3.3min\n",
            "[CV] END learning_rate=0.15, max_depth=5, min_samples_leaf=0.10974874538564039, min_samples_split=0.02, n_estimators=400; total time= 3.3min\n",
            "[CV] END learning_rate=0.15, max_depth=5, min_samples_leaf=0.10974874538564039, min_samples_split=0.02, n_estimators=400; total time= 1.4min\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.14831583903250545, max_depth=5, min_samples_leaf=0.1497335233142639, min_samples_split=0.5385440554276435, n_estimators=395; total time= 2.1min\n",
            "[CV] END learning_rate=0.14831583903250545, max_depth=5, min_samples_leaf=0.1497335233142639, min_samples_split=0.5385440554276435, n_estimators=395; total time= 2.1min\n",
            "[CV] END learning_rate=0.14831583903250545, max_depth=5, min_samples_leaf=0.1497335233142639, min_samples_split=0.5385440554276435, n_estimators=395; total time= 2.1min\n",
            "[CV] END learning_rate=0.14831583903250545, max_depth=5, min_samples_leaf=0.1497335233142639, min_samples_split=0.5385440554276435, n_estimators=395; total time= 2.1min\n",
            "[CV] END learning_rate=0.14831583903250545, max_depth=5, min_samples_leaf=0.1497335233142639, min_samples_split=0.5385440554276435, n_estimators=395; total time=  52.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.15, max_depth=4, min_samples_leaf=0.2849979281818991, min_samples_split=0.02, n_estimators=400; total time= 1.8min\n",
            "[CV] END learning_rate=0.15, max_depth=4, min_samples_leaf=0.2849979281818991, min_samples_split=0.02, n_estimators=400; total time= 1.8min\n",
            "[CV] END learning_rate=0.15, max_depth=4, min_samples_leaf=0.2849979281818991, min_samples_split=0.02, n_estimators=400; total time= 1.8min\n",
            "[CV] END learning_rate=0.15, max_depth=4, min_samples_leaf=0.2849979281818991, min_samples_split=0.02, n_estimators=400; total time= 1.8min\n",
            "[CV] END learning_rate=0.15, max_depth=4, min_samples_leaf=0.2849979281818991, min_samples_split=0.02, n_estimators=400; total time=  45.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.6, n_estimators=50; total time=  11.7s\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.6, n_estimators=50; total time=  11.7s\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.6, n_estimators=50; total time=  11.8s\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.6, n_estimators=50; total time=  11.9s\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.6, n_estimators=50; total time=   5.3s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.1491815339840052, max_depth=2, min_samples_leaf=0.18371257815588699, min_samples_split=0.1997996696717439, n_estimators=376; total time= 1.1min\n",
            "[CV] END learning_rate=0.1491815339840052, max_depth=2, min_samples_leaf=0.18371257815588699, min_samples_split=0.1997996696717439, n_estimators=376; total time= 1.1min\n",
            "[CV] END learning_rate=0.1491815339840052, max_depth=2, min_samples_leaf=0.18371257815588699, min_samples_split=0.1997996696717439, n_estimators=376; total time= 1.1min\n",
            "[CV] END learning_rate=0.1491815339840052, max_depth=2, min_samples_leaf=0.18371257815588699, min_samples_split=0.1997996696717439, n_estimators=376; total time= 1.1min\n",
            "[CV] END learning_rate=0.1491815339840052, max_depth=2, min_samples_leaf=0.18371257815588699, min_samples_split=0.1997996696717439, n_estimators=376; total time=  29.2s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.13802814261422874, max_depth=1, min_samples_leaf=0.30509208733490306, min_samples_split=0.5782156858067699, n_estimators=400; total time=  47.2s\n",
            "[CV] END learning_rate=0.13802814261422874, max_depth=1, min_samples_leaf=0.30509208733490306, min_samples_split=0.5782156858067699, n_estimators=400; total time=  47.3s\n",
            "[CV] END learning_rate=0.13802814261422874, max_depth=1, min_samples_leaf=0.30509208733490306, min_samples_split=0.5782156858067699, n_estimators=400; total time=  47.3s\n",
            "[CV] END learning_rate=0.13802814261422874, max_depth=1, min_samples_leaf=0.30509208733490306, min_samples_split=0.5782156858067699, n_estimators=400; total time=  47.3s\n",
            "[CV] END learning_rate=0.13802814261422874, max_depth=1, min_samples_leaf=0.30509208733490306, min_samples_split=0.5782156858067699, n_estimators=400; total time=  18.7s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.053525358703537966, max_depth=3, min_samples_leaf=0.48009794766393216, min_samples_split=0.02091689920200871, n_estimators=397; total time=  45.8s\n",
            "[CV] END learning_rate=0.053525358703537966, max_depth=3, min_samples_leaf=0.48009794766393216, min_samples_split=0.02091689920200871, n_estimators=397; total time=  45.8s\n",
            "[CV] END learning_rate=0.053525358703537966, max_depth=3, min_samples_leaf=0.48009794766393216, min_samples_split=0.02091689920200871, n_estimators=397; total time=  45.9s\n",
            "[CV] END learning_rate=0.053525358703537966, max_depth=3, min_samples_leaf=0.48009794766393216, min_samples_split=0.02091689920200871, n_estimators=397; total time=  46.2s\n",
            "[CV] END learning_rate=0.053525358703537966, max_depth=3, min_samples_leaf=0.48009794766393216, min_samples_split=0.02091689920200871, n_estimators=397; total time=  44.3s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=0.14652140962276247, min_samples_split=0.02, n_estimators=400; total time= 2.7min\n",
            "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=0.14652140962276247, min_samples_split=0.02, n_estimators=400; total time= 2.7min\n",
            "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=0.14652140962276247, min_samples_split=0.02, n_estimators=400; total time= 2.7min\n",
            "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=0.14652140962276247, min_samples_split=0.02, n_estimators=400; total time= 2.7min\n",
            "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=0.14652140962276247, min_samples_split=0.02, n_estimators=400; total time=  58.2s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.07639199835383187, min_samples_split=0.02, n_estimators=400; total time= 3.8min\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.07639199835383187, min_samples_split=0.02, n_estimators=400; total time= 3.9min\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.07639199835383187, min_samples_split=0.02, n_estimators=400; total time= 3.9min\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.07639199835383187, min_samples_split=0.02, n_estimators=400; total time= 3.9min\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.07639199835383187, min_samples_split=0.02, n_estimators=400; total time= 1.5min\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=0.3455623003717192, min_samples_split=0.02, n_estimators=400; total time= 1.3min\n",
            "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=0.3455623003717192, min_samples_split=0.02, n_estimators=400; total time= 1.3min\n",
            "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=0.3455623003717192, min_samples_split=0.02, n_estimators=400; total time= 1.3min\n",
            "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=0.3455623003717192, min_samples_split=0.02, n_estimators=400; total time= 1.3min\n",
            "[CV] END learning_rate=0.05, max_depth=6, min_samples_leaf=0.3455623003717192, min_samples_split=0.02, n_estimators=400; total time=  30.6s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.07426652248278372, max_depth=2, min_samples_leaf=0.19481138840839896, min_samples_split=0.03645373997880422, n_estimators=392; total time= 2.0min\n",
            "[CV] END learning_rate=0.07426652248278372, max_depth=2, min_samples_leaf=0.19481138840839896, min_samples_split=0.03645373997880422, n_estimators=392; total time= 2.0min\n",
            "[CV] END learning_rate=0.07426652248278372, max_depth=2, min_samples_leaf=0.19481138840839896, min_samples_split=0.03645373997880422, n_estimators=392; total time= 2.0min\n",
            "[CV] END learning_rate=0.07426652248278372, max_depth=2, min_samples_leaf=0.19481138840839896, min_samples_split=0.03645373997880422, n_estimators=392; total time= 2.0min\n",
            "[CV] END learning_rate=0.07426652248278372, max_depth=2, min_samples_leaf=0.19481138840839896, min_samples_split=0.03645373997880422, n_estimators=392; total time=  45.7s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.22863981430081853, min_samples_split=0.6, n_estimators=400; total time= 1.7min\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.22863981430081853, min_samples_split=0.6, n_estimators=400; total time= 1.7min\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.22863981430081853, min_samples_split=0.6, n_estimators=400; total time= 1.7min\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.22863981430081853, min_samples_split=0.6, n_estimators=400; total time= 1.7min\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.22863981430081853, min_samples_split=0.6, n_estimators=400; total time=  42.7s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.14771641997446305, max_depth=1, min_samples_leaf=0.09614022566736542, min_samples_split=0.09255942108357713, n_estimators=354; total time= 3.1min\n",
            "[CV] END learning_rate=0.14771641997446305, max_depth=1, min_samples_leaf=0.09614022566736542, min_samples_split=0.09255942108357713, n_estimators=354; total time= 3.1min\n",
            "[CV] END learning_rate=0.14771641997446305, max_depth=1, min_samples_leaf=0.09614022566736542, min_samples_split=0.09255942108357713, n_estimators=354; total time= 3.1min\n",
            "[CV] END learning_rate=0.14771641997446305, max_depth=1, min_samples_leaf=0.09614022566736542, min_samples_split=0.09255942108357713, n_estimators=354; total time= 3.1min\n",
            "[CV] END learning_rate=0.14771641997446305, max_depth=1, min_samples_leaf=0.09614022566736542, min_samples_split=0.09255942108357713, n_estimators=354; total time=  27.9s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=400; total time= 5.1min\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=400; total time= 5.1min\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=400; total time= 5.1min\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=400; total time= 5.1min\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=400; total time= 1.6min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The objective has been evaluated at this point before.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=400; total time= 4.5min\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=400; total time= 4.6min\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=400; total time= 4.6min\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=400; total time= 4.6min\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=400; total time= 1.6min\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.1282567428821437, max_depth=6, min_samples_leaf=0.17788496961245143, min_samples_split=0.023231421809895646, n_estimators=340; total time= 1.9min\n",
            "[CV] END learning_rate=0.1282567428821437, max_depth=6, min_samples_leaf=0.17788496961245143, min_samples_split=0.023231421809895646, n_estimators=340; total time= 1.9min\n",
            "[CV] END learning_rate=0.1282567428821437, max_depth=6, min_samples_leaf=0.17788496961245143, min_samples_split=0.023231421809895646, n_estimators=340; total time= 1.9min\n",
            "[CV] END learning_rate=0.1282567428821437, max_depth=6, min_samples_leaf=0.17788496961245143, min_samples_split=0.023231421809895646, n_estimators=340; total time= 1.9min\n",
            "[CV] END learning_rate=0.1282567428821437, max_depth=6, min_samples_leaf=0.17788496961245143, min_samples_split=0.023231421809895646, n_estimators=340; total time=  43.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The objective has been evaluated at this point before.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=400; total time= 4.7min\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=400; total time= 4.7min\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=400; total time= 4.7min\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=400; total time= 4.8min\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.05, min_samples_split=0.02, n_estimators=400; total time= 1.6min\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.13584833190465406, min_samples_split=0.02, n_estimators=400; total time= 4.2min\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.13584833190465406, min_samples_split=0.02, n_estimators=400; total time= 4.2min\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.13584833190465406, min_samples_split=0.02, n_estimators=400; total time= 4.3min\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.13584833190465406, min_samples_split=0.02, n_estimators=400; total time= 4.3min\n",
            "[CV] END learning_rate=0.15, max_depth=6, min_samples_leaf=0.13584833190465406, min_samples_split=0.02, n_estimators=400; total time= 1.9min\n",
            "learning_rate: 0.15 n_estimators: 400 max_depth: 6 min_samples_leaf: 0.05 min_samples_split: 0.02\n"
          ]
        }
      ],
      "source": [
        "df_error_train = pd.DataFrame()\n",
        "x_model = x_train.copy().drop(['Wine_strength'],axis=1)\n",
        "\n",
        "y_model = y_train.copy()\n",
        "cv = separation(x_model, y_model, 5, 0.2)\n",
        "count = 0\n",
        "\n",
        "class_GBC = GradientBoostingClassifier()\n",
        "\n",
        "search_space = {\"learning_rate\": Real(0.05, 0.15),\n",
        "    \"n_estimators\": Integer(50, 400),\n",
        "    \"max_depth\": Integer(1, 6),\n",
        "    \"min_samples_leaf\": Real(0.05, 0.5),\n",
        "    \"min_samples_split\": Real(0.02, 0.6)}\n",
        "\n",
        "sc = MinMaxScaler(feature_range=(0, 1))\n",
        "x_train01 = sc.fit_transform(x_model)\n",
        "\n",
        "opt_GBC = BayesSearchCV(estimator = class_GBC, search_spaces=search_space, cv=separation(x_model, y_model,5, 0.2), n_iter=32, verbose=2, n_jobs=-1)\n",
        "opt_GBC.fit(x_train01, y_model)\n",
        "\n",
        "learning_rate = opt_GBC.best_estimator_.learning_rate\n",
        "n_estimators = opt_GBC.best_estimator_.n_estimators\n",
        "max_depth = opt_GBC.best_estimator_.max_depth\n",
        "min_samples_leaf = opt_GBC.best_estimator_.min_samples_leaf\n",
        "min_samples_split = opt_GBC.best_estimator_.min_samples_split\n",
        "\n",
        "print('learning_rate:', learning_rate,'n_estimators:', n_estimators, 'max_depth:', max_depth, 'min_samples_leaf:', min_samples_leaf,'min_samples_split:', min_samples_split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WN1DQNmsYnk8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_score: 0.6973512809379071\n",
            "Accuracy: 0.4599371505272388\n",
            "f1_train: 0.7578192875760209\n",
            "Accuracy_train: 0.576678657138885\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_score: 0.6951801997394702\n",
            "Accuracy: 0.46878697544083286\n",
            "f1_train: 0.7611859252823632\n",
            "Accuracy_train: 0.5845390395856279\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_score: 0.7129830655666523\n",
            "Accuracy: 0.4428645256912045\n",
            "f1_train: 0.7572762814943529\n",
            "Accuracy_train: 0.5891734945108346\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_score: 0.6973512809379071\n",
            "Accuracy: 0.47650294567587803\n",
            "f1_train: 0.7573848827106864\n",
            "Accuracy_train: 0.578194577653244\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_score: 0.6990881458966566\n",
            "Accuracy: 0.46551770854669733\n",
            "f1_train: 0.7602085143353605\n",
            "Accuracy_train: 0.5779805280427828\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gradient Boosting Classification0</th>\n",
              "      <th>Gradient Boosting Classification1</th>\n",
              "      <th>Gradient Boosting Classification2</th>\n",
              "      <th>Gradient Boosting Classification3</th>\n",
              "      <th>Gradient Boosting Classification4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.757819</td>\n",
              "      <td>0.761186</td>\n",
              "      <td>0.757276</td>\n",
              "      <td>0.757385</td>\n",
              "      <td>0.760209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.697351</td>\n",
              "      <td>0.695180</td>\n",
              "      <td>0.712983</td>\n",
              "      <td>0.697351</td>\n",
              "      <td>0.699088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.576679</td>\n",
              "      <td>0.584539</td>\n",
              "      <td>0.589173</td>\n",
              "      <td>0.578195</td>\n",
              "      <td>0.577981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.459937</td>\n",
              "      <td>0.468787</td>\n",
              "      <td>0.442865</td>\n",
              "      <td>0.476503</td>\n",
              "      <td>0.465518</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Gradient Boosting Classification0  Gradient Boosting Classification1  \\\n",
              "0                           0.757819                           0.761186   \n",
              "1                           0.697351                           0.695180   \n",
              "2                           0.576679                           0.584539   \n",
              "3                           0.459937                           0.468787   \n",
              "\n",
              "   Gradient Boosting Classification2  Gradient Boosting Classification3  \\\n",
              "0                           0.757276                           0.757385   \n",
              "1                           0.712983                           0.697351   \n",
              "2                           0.589173                           0.578195   \n",
              "3                           0.442865                           0.476503   \n",
              "\n",
              "   Gradient Boosting Classification4  \n",
              "0                           0.760209  \n",
              "1                           0.699088  \n",
              "2                           0.577981  \n",
              "3                           0.465518  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count = 0\n",
        "GBC_df = x_model[:]\n",
        "GBC_df['Sugar'] = y_model\n",
        "\n",
        "for train_idx, val_idx in cv:\n",
        "    x_train_mod, x_test_mod = x_model.iloc[train_idx], x_model.iloc[val_idx]\n",
        "    y_train_mod, y_test_mod = y_model.iloc[train_idx], y_model.iloc[val_idx]\n",
        "\n",
        "    sc = MinMaxScaler(feature_range=(0, 1))\n",
        "    x_train_mod = sc.fit_transform(x_train_mod)\n",
        "    x_test_mod = sc.transform(x_test_mod)\n",
        "\n",
        "    class_GBC = GradientBoostingClassifier(learning_rate = learning_rate, n_estimators = n_estimators, max_depth= max_depth, min_samples_leaf= min_samples_leaf, min_samples_split= min_samples_split)\n",
        "    class_GBC.fit(x_train_mod, y_train_mod)\n",
        "    y_pred = class_GBC.predict(x_test_mod)\n",
        "    y1_pred = class_GBC.predict(x_train_mod)\n",
        "\n",
        "    GBC_df['Strength_train' + str(count)] = None\n",
        "    GBC_df['Strength_test' + str(count)] = None\n",
        "    GBC_df['Strength_train' + str(count)].iloc[train_idx] = y1_pred\n",
        "    GBC_df['Strength_test' + str(count)].iloc[val_idx] = y_pred\n",
        "\n",
        "    df_error_train['Gradient Boosting Classification' + str(count)] = metrics(class_GBC, x_train_mod, y_train_mod, y_test_mod, y_pred, y1_pred)\n",
        "    count +=1\n",
        "df_error_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe5Xj7N3ZUvJ"
      },
      "source": [
        "## 4. Extreme Gradient Boosting (XGBoost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uWIlzb4dZYLs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.631238489676593, max_depth=19, n_estimators=230, subsample=0.34141914849869864; total time=  32.8s\n",
            "[CV] END colsample_bytree=0.631238489676593, max_depth=19, n_estimators=230, subsample=0.34141914849869864; total time=  33.0s\n",
            "[CV] END colsample_bytree=0.631238489676593, max_depth=19, n_estimators=230, subsample=0.34141914849869864; total time=  33.1s\n",
            "[CV] END colsample_bytree=0.631238489676593, max_depth=19, n_estimators=230, subsample=0.34141914849869864; total time=  33.0s\n",
            "[CV] END colsample_bytree=0.631238489676593, max_depth=19, n_estimators=230, subsample=0.34141914849869864; total time=  11.8s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.5392478640826195, max_depth=4, n_estimators=236, subsample=0.33627810759935595; total time=   5.6s\n",
            "[CV] END colsample_bytree=0.5392478640826195, max_depth=4, n_estimators=236, subsample=0.33627810759935595; total time=   5.7s\n",
            "[CV] END colsample_bytree=0.5392478640826195, max_depth=4, n_estimators=236, subsample=0.33627810759935595; total time=   5.7s\n",
            "[CV] END colsample_bytree=0.5392478640826195, max_depth=4, n_estimators=236, subsample=0.33627810759935595; total time=   5.7s\n",
            "[CV] END colsample_bytree=0.5392478640826195, max_depth=4, n_estimators=236, subsample=0.33627810759935595; total time=   3.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.1690728773145076, max_depth=12, n_estimators=278, subsample=0.3009910559538997; total time=  21.0s\n",
            "[CV] END colsample_bytree=0.1690728773145076, max_depth=12, n_estimators=278, subsample=0.3009910559538997; total time=  21.1s\n",
            "[CV] END colsample_bytree=0.1690728773145076, max_depth=12, n_estimators=278, subsample=0.3009910559538997; total time=  21.1s\n",
            "[CV] END colsample_bytree=0.1690728773145076, max_depth=12, n_estimators=278, subsample=0.3009910559538997; total time=  21.2s\n",
            "[CV] END colsample_bytree=0.1690728773145076, max_depth=12, n_estimators=278, subsample=0.3009910559538997; total time=   8.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.8025745814918026, max_depth=12, n_estimators=304, subsample=0.10588671313646125; total time=  20.1s\n",
            "[CV] END colsample_bytree=0.8025745814918026, max_depth=12, n_estimators=304, subsample=0.10588671313646125; total time=  20.3s\n",
            "[CV] END colsample_bytree=0.8025745814918026, max_depth=12, n_estimators=304, subsample=0.10588671313646125; total time=  20.5s\n",
            "[CV] END colsample_bytree=0.8025745814918026, max_depth=12, n_estimators=304, subsample=0.10588671313646125; total time=  20.6s\n",
            "[CV] END colsample_bytree=0.8025745814918026, max_depth=12, n_estimators=304, subsample=0.10588671313646125; total time=   9.4s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.629423306393749, max_depth=8, n_estimators=143, subsample=0.47764749908649246; total time=  10.4s\n",
            "[CV] END colsample_bytree=0.629423306393749, max_depth=8, n_estimators=143, subsample=0.47764749908649246; total time=  10.5s\n",
            "[CV] END colsample_bytree=0.629423306393749, max_depth=8, n_estimators=143, subsample=0.47764749908649246; total time=  10.5s\n",
            "[CV] END colsample_bytree=0.629423306393749, max_depth=8, n_estimators=143, subsample=0.47764749908649246; total time=  10.6s\n",
            "[CV] END colsample_bytree=0.629423306393749, max_depth=8, n_estimators=143, subsample=0.47764749908649246; total time=   5.2s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.970895498591644, max_depth=17, n_estimators=116, subsample=0.9399317761665988; total time=  28.0s\n",
            "[CV] END colsample_bytree=0.970895498591644, max_depth=17, n_estimators=116, subsample=0.9399317761665988; total time=  28.1s\n",
            "[CV] END colsample_bytree=0.970895498591644, max_depth=17, n_estimators=116, subsample=0.9399317761665988; total time=  28.1s\n",
            "[CV] END colsample_bytree=0.970895498591644, max_depth=17, n_estimators=116, subsample=0.9399317761665988; total time=  28.2s\n",
            "[CV] END colsample_bytree=0.970895498591644, max_depth=17, n_estimators=116, subsample=0.9399317761665988; total time=  11.9s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.4647688026682802, max_depth=26, n_estimators=68, subsample=0.46587736322966355; total time=  12.4s\n",
            "[CV] END colsample_bytree=0.4647688026682802, max_depth=26, n_estimators=68, subsample=0.46587736322966355; total time=  12.3s\n",
            "[CV] END colsample_bytree=0.4647688026682802, max_depth=26, n_estimators=68, subsample=0.46587736322966355; total time=  12.4s\n",
            "[CV] END colsample_bytree=0.4647688026682802, max_depth=26, n_estimators=68, subsample=0.46587736322966355; total time=  12.4s\n",
            "[CV] END colsample_bytree=0.4647688026682802, max_depth=26, n_estimators=68, subsample=0.46587736322966355; total time=   5.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.3210771192469851, max_depth=8, n_estimators=175, subsample=0.7038788068492874; total time=  11.7s\n",
            "[CV] END colsample_bytree=0.3210771192469851, max_depth=8, n_estimators=175, subsample=0.7038788068492874; total time=  11.7s\n",
            "[CV] END colsample_bytree=0.3210771192469851, max_depth=8, n_estimators=175, subsample=0.7038788068492874; total time=  11.7s\n",
            "[CV] END colsample_bytree=0.3210771192469851, max_depth=8, n_estimators=175, subsample=0.7038788068492874; total time=  12.3s\n",
            "[CV] END colsample_bytree=0.3210771192469851, max_depth=8, n_estimators=175, subsample=0.7038788068492874; total time=   4.9s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.5058345669729697, max_depth=13, n_estimators=337, subsample=0.2571123623177268; total time=  31.0s\n",
            "[CV] END colsample_bytree=0.5058345669729697, max_depth=13, n_estimators=337, subsample=0.2571123623177268; total time=  31.1s\n",
            "[CV] END colsample_bytree=0.5058345669729697, max_depth=13, n_estimators=337, subsample=0.2571123623177268; total time=  31.5s\n",
            "[CV] END colsample_bytree=0.5058345669729697, max_depth=13, n_estimators=337, subsample=0.2571123623177268; total time=  31.6s\n",
            "[CV] END colsample_bytree=0.5058345669729697, max_depth=13, n_estimators=337, subsample=0.2571123623177268; total time=  13.5s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.3054986251450767, max_depth=25, n_estimators=246, subsample=0.7881669382408741; total time=  35.7s\n",
            "[CV] END colsample_bytree=0.3054986251450767, max_depth=25, n_estimators=246, subsample=0.7881669382408741; total time=  35.8s\n",
            "[CV] END colsample_bytree=0.3054986251450767, max_depth=25, n_estimators=246, subsample=0.7881669382408741; total time=  35.9s\n",
            "[CV] END colsample_bytree=0.3054986251450767, max_depth=25, n_estimators=246, subsample=0.7881669382408741; total time=  36.3s\n",
            "[CV] END colsample_bytree=0.3054986251450767, max_depth=25, n_estimators=246, subsample=0.7881669382408741; total time=  13.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.12494338349506712, max_depth=2, n_estimators=350, subsample=0.5288063944594098; total time=   5.6s\n",
            "[CV] END colsample_bytree=0.12494338349506712, max_depth=2, n_estimators=350, subsample=0.5288063944594098; total time=   5.6s\n",
            "[CV] END colsample_bytree=0.12494338349506712, max_depth=2, n_estimators=350, subsample=0.5288063944594098; total time=   5.7s\n",
            "[CV] END colsample_bytree=0.12494338349506712, max_depth=2, n_estimators=350, subsample=0.5288063944594098; total time=   5.6s\n",
            "[CV] END colsample_bytree=0.12494338349506712, max_depth=2, n_estimators=350, subsample=0.5288063944594098; total time=   3.8s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.8401307143797474, max_depth=18, n_estimators=315, subsample=0.582616238161695; total time=  52.9s\n",
            "[CV] END colsample_bytree=0.8401307143797474, max_depth=18, n_estimators=315, subsample=0.582616238161695; total time=  53.2s\n",
            "[CV] END colsample_bytree=0.8401307143797474, max_depth=18, n_estimators=315, subsample=0.582616238161695; total time=  53.2s\n",
            "[CV] END colsample_bytree=0.8401307143797474, max_depth=18, n_estimators=315, subsample=0.582616238161695; total time=  53.7s\n",
            "[CV] END colsample_bytree=0.8401307143797474, max_depth=18, n_estimators=315, subsample=0.582616238161695; total time=  23.3s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.49508907103243605, max_depth=2, n_estimators=249, subsample=0.9985349761786896; total time=   4.9s\n",
            "[CV] END colsample_bytree=0.49508907103243605, max_depth=2, n_estimators=249, subsample=0.9985349761786896; total time=   4.9s\n",
            "[CV] END colsample_bytree=0.49508907103243605, max_depth=2, n_estimators=249, subsample=0.9985349761786896; total time=   4.9s\n",
            "[CV] END colsample_bytree=0.49508907103243605, max_depth=2, n_estimators=249, subsample=0.9985349761786896; total time=   5.0s\n",
            "[CV] END colsample_bytree=0.49508907103243605, max_depth=2, n_estimators=249, subsample=0.9985349761786896; total time=   1.8s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.1719026870890617, max_depth=2, n_estimators=59, subsample=0.9412301572686004; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.1719026870890617, max_depth=2, n_estimators=59, subsample=0.9412301572686004; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.1719026870890617, max_depth=2, n_estimators=59, subsample=0.9412301572686004; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.1719026870890617, max_depth=2, n_estimators=59, subsample=0.9412301572686004; total time=   0.9s\n",
            "[CV] END colsample_bytree=0.1719026870890617, max_depth=2, n_estimators=59, subsample=0.9412301572686004; total time=   0.5s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.6939947199559402, max_depth=2, n_estimators=311, subsample=0.91544766732525; total time=   5.5s\n",
            "[CV] END colsample_bytree=0.6939947199559402, max_depth=2, n_estimators=311, subsample=0.91544766732525; total time=   5.4s\n",
            "[CV] END colsample_bytree=0.6939947199559402, max_depth=2, n_estimators=311, subsample=0.91544766732525; total time=   5.5s\n",
            "[CV] END colsample_bytree=0.6939947199559402, max_depth=2, n_estimators=311, subsample=0.91544766732525; total time=   5.5s\n",
            "[CV] END colsample_bytree=0.6939947199559402, max_depth=2, n_estimators=311, subsample=0.91544766732525; total time=   2.7s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.22585922480785425, max_depth=10, n_estimators=350, subsample=1.0; total time=  20.6s\n",
            "[CV] END colsample_bytree=0.22585922480785425, max_depth=10, n_estimators=350, subsample=1.0; total time=  20.7s\n",
            "[CV] END colsample_bytree=0.22585922480785425, max_depth=10, n_estimators=350, subsample=1.0; total time=  20.8s\n",
            "[CV] END colsample_bytree=0.22585922480785425, max_depth=10, n_estimators=350, subsample=1.0; total time=  20.8s\n",
            "[CV] END colsample_bytree=0.22585922480785425, max_depth=10, n_estimators=350, subsample=1.0; total time=   8.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.9794200912146573, max_depth=10, n_estimators=53, subsample=0.05837453711576243; total time=   2.9s\n",
            "[CV] END colsample_bytree=0.9794200912146573, max_depth=10, n_estimators=53, subsample=0.05837453711576243; total time=   2.9s\n",
            "[CV] END colsample_bytree=0.9794200912146573, max_depth=10, n_estimators=53, subsample=0.05837453711576243; total time=   2.9s\n",
            "[CV] END colsample_bytree=0.9794200912146573, max_depth=10, n_estimators=53, subsample=0.05837453711576243; total time=   2.9s\n",
            "[CV] END colsample_bytree=0.9794200912146573, max_depth=10, n_estimators=53, subsample=0.05837453711576243; total time=   1.2s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.5128496432033337, max_depth=2, n_estimators=350, subsample=0.7184578089739925; total time=   4.9s[CV] END colsample_bytree=0.5128496432033337, max_depth=2, n_estimators=350, subsample=0.7184578089739925; total time=   4.9s\n",
            "\n",
            "[CV] END colsample_bytree=0.5128496432033337, max_depth=2, n_estimators=350, subsample=0.7184578089739925; total time=   4.9s\n",
            "[CV] END colsample_bytree=0.5128496432033337, max_depth=2, n_estimators=350, subsample=0.7184578089739925; total time=   4.9s\n",
            "[CV] END colsample_bytree=0.5128496432033337, max_depth=2, n_estimators=350, subsample=0.7184578089739925; total time=   2.7s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.1161434581826519, max_depth=4, n_estimators=51, subsample=0.06906268861489669; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.1161434581826519, max_depth=4, n_estimators=51, subsample=0.06906268861489669; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.1161434581826519, max_depth=4, n_estimators=51, subsample=0.06906268861489669; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.1161434581826519, max_depth=4, n_estimators=51, subsample=0.06906268861489669; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.1161434581826519, max_depth=4, n_estimators=51, subsample=0.06906268861489669; total time=   0.5s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.26745093164386385, max_depth=30, n_estimators=50, subsample=1.0; total time=  10.5s\n",
            "[CV] END colsample_bytree=0.26745093164386385, max_depth=30, n_estimators=50, subsample=1.0; total time=  10.5s\n",
            "[CV] END colsample_bytree=0.26745093164386385, max_depth=30, n_estimators=50, subsample=1.0; total time=  10.5s\n",
            "[CV] END colsample_bytree=0.26745093164386385, max_depth=30, n_estimators=50, subsample=1.0; total time=  10.6s\n",
            "[CV] END colsample_bytree=0.26745093164386385, max_depth=30, n_estimators=50, subsample=1.0; total time=   4.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.49712274102824305, max_depth=30, n_estimators=62, subsample=0.6964847704971284; total time=  13.4s\n",
            "[CV] END colsample_bytree=0.49712274102824305, max_depth=30, n_estimators=62, subsample=0.6964847704971284; total time=  13.4s\n",
            "[CV] END colsample_bytree=0.49712274102824305, max_depth=30, n_estimators=62, subsample=0.6964847704971284; total time=  13.5s\n",
            "[CV] END colsample_bytree=0.49712274102824305, max_depth=30, n_estimators=62, subsample=0.6964847704971284; total time=  13.6s\n",
            "[CV] END colsample_bytree=0.49712274102824305, max_depth=30, n_estimators=62, subsample=0.6964847704971284; total time=   8.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.2118257169938097, max_depth=3, n_estimators=58, subsample=0.43719791329388447; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.2118257169938097, max_depth=3, n_estimators=58, subsample=0.43719791329388447; total time=   1.2s\n",
            "[CV] END colsample_bytree=0.2118257169938097, max_depth=3, n_estimators=58, subsample=0.43719791329388447; total time=   1.2s\n",
            "[CV] END colsample_bytree=0.2118257169938097, max_depth=3, n_estimators=58, subsample=0.43719791329388447; total time=   1.1s\n",
            "[CV] END colsample_bytree=0.2118257169938097, max_depth=3, n_estimators=58, subsample=0.43719791329388447; total time=   0.5s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.06891439607239772, max_depth=2, n_estimators=287, subsample=0.7903472632529281; total time=   4.2s\n",
            "[CV] END colsample_bytree=0.06891439607239772, max_depth=2, n_estimators=287, subsample=0.7903472632529281; total time=   4.3s\n",
            "[CV] END colsample_bytree=0.06891439607239772, max_depth=2, n_estimators=287, subsample=0.7903472632529281; total time=   4.3s\n",
            "[CV] END colsample_bytree=0.06891439607239772, max_depth=2, n_estimators=287, subsample=0.7903472632529281; total time=   4.3s\n",
            "[CV] END colsample_bytree=0.06891439607239772, max_depth=2, n_estimators=287, subsample=0.7903472632529281; total time=   2.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=1.0, max_depth=2, n_estimators=247, subsample=0.6347610715803091; total time=   5.0s\n",
            "[CV] END colsample_bytree=1.0, max_depth=2, n_estimators=247, subsample=0.6347610715803091; total time=   5.0s\n",
            "[CV] END colsample_bytree=1.0, max_depth=2, n_estimators=247, subsample=0.6347610715803091; total time=   5.1s\n",
            "[CV] END colsample_bytree=1.0, max_depth=2, n_estimators=247, subsample=0.6347610715803091; total time=   6.1s\n",
            "[CV] END colsample_bytree=1.0, max_depth=2, n_estimators=247, subsample=0.6347610715803091; total time=   3.0s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=1.0, max_depth=2, n_estimators=350, subsample=1.0; total time=   6.3s\n",
            "[CV] END colsample_bytree=1.0, max_depth=2, n_estimators=350, subsample=1.0; total time=   6.4s\n",
            "[CV] END colsample_bytree=1.0, max_depth=2, n_estimators=350, subsample=1.0; total time=   6.4s\n",
            "[CV] END colsample_bytree=1.0, max_depth=2, n_estimators=350, subsample=1.0; total time=   6.4s\n",
            "[CV] END colsample_bytree=1.0, max_depth=2, n_estimators=350, subsample=1.0; total time=   2.6s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=1.0, max_depth=30, n_estimators=350, subsample=1.0; total time= 1.1min\n",
            "[CV] END colsample_bytree=1.0, max_depth=30, n_estimators=350, subsample=1.0; total time= 1.1min\n",
            "[CV] END colsample_bytree=1.0, max_depth=30, n_estimators=350, subsample=1.0; total time= 1.1min\n",
            "[CV] END colsample_bytree=1.0, max_depth=30, n_estimators=350, subsample=1.0; total time= 1.1min\n",
            "[CV] END colsample_bytree=1.0, max_depth=30, n_estimators=350, subsample=1.0; total time=  28.3s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=1.0, max_depth=2, n_estimators=350, subsample=0.7623757937049288; total time=   6.6s\n",
            "[CV] END colsample_bytree=1.0, max_depth=2, n_estimators=350, subsample=0.7623757937049288; total time=   6.6s\n",
            "[CV] END colsample_bytree=1.0, max_depth=2, n_estimators=350, subsample=0.7623757937049288; total time=   6.7s\n",
            "[CV] END colsample_bytree=1.0, max_depth=2, n_estimators=350, subsample=0.7623757937049288; total time=   6.7s\n",
            "[CV] END colsample_bytree=1.0, max_depth=2, n_estimators=350, subsample=0.7623757937049288; total time=   3.3s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.12087004701098109, max_depth=30, n_estimators=215, subsample=0.07665360854146855; total time=   9.2s\n",
            "[CV] END colsample_bytree=0.12087004701098109, max_depth=30, n_estimators=215, subsample=0.07665360854146855; total time=   9.3s\n",
            "[CV] END colsample_bytree=0.12087004701098109, max_depth=30, n_estimators=215, subsample=0.07665360854146855; total time=   9.3s\n",
            "[CV] END colsample_bytree=0.12087004701098109, max_depth=30, n_estimators=215, subsample=0.07665360854146855; total time=   9.4s\n",
            "[CV] END colsample_bytree=0.12087004701098109, max_depth=30, n_estimators=215, subsample=0.07665360854146855; total time=   3.8s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=1.0, max_depth=2, n_estimators=246, subsample=1.0; total time=   4.0s\n",
            "[CV] END colsample_bytree=1.0, max_depth=2, n_estimators=246, subsample=1.0; total time=   4.1s\n",
            "[CV] END colsample_bytree=1.0, max_depth=2, n_estimators=246, subsample=1.0; total time=   4.1s\n",
            "[CV] END colsample_bytree=1.0, max_depth=2, n_estimators=246, subsample=1.0; total time=   4.0s\n",
            "[CV] END colsample_bytree=1.0, max_depth=2, n_estimators=246, subsample=1.0; total time=   2.1s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.985723478245707, max_depth=5, n_estimators=57, subsample=0.6152974658215927; total time=   2.5s\n",
            "[CV] END colsample_bytree=0.985723478245707, max_depth=5, n_estimators=57, subsample=0.6152974658215927; total time=   2.6s\n",
            "[CV] END colsample_bytree=0.985723478245707, max_depth=5, n_estimators=57, subsample=0.6152974658215927; total time=   2.6s\n",
            "[CV] END colsample_bytree=0.985723478245707, max_depth=5, n_estimators=57, subsample=0.6152974658215927; total time=   2.6s\n",
            "[CV] END colsample_bytree=0.985723478245707, max_depth=5, n_estimators=57, subsample=0.6152974658215927; total time=   1.7s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.09771019165552935, max_depth=30, n_estimators=311, subsample=0.42838826080820663; total time=  26.5s\n",
            "[CV] END colsample_bytree=0.09771019165552935, max_depth=30, n_estimators=311, subsample=0.42838826080820663; total time=  26.7s\n",
            "[CV] END colsample_bytree=0.09771019165552935, max_depth=30, n_estimators=311, subsample=0.42838826080820663; total time=  26.8s\n",
            "[CV] END colsample_bytree=0.09771019165552935, max_depth=30, n_estimators=311, subsample=0.42838826080820663; total time=  26.8s\n",
            "[CV] END colsample_bytree=0.09771019165552935, max_depth=30, n_estimators=311, subsample=0.42838826080820663; total time=   9.2s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV] END colsample_bytree=0.8965382860680635, max_depth=30, n_estimators=56, subsample=0.252549911243657; total time=   9.6s\n",
            "[CV] END colsample_bytree=0.8965382860680635, max_depth=30, n_estimators=56, subsample=0.252549911243657; total time=   9.7s\n",
            "[CV] END colsample_bytree=0.8965382860680635, max_depth=30, n_estimators=56, subsample=0.252549911243657; total time=   9.8s\n",
            "[CV] END colsample_bytree=0.8965382860680635, max_depth=30, n_estimators=56, subsample=0.252549911243657; total time=   9.9s\n",
            "[CV] END colsample_bytree=0.8965382860680635, max_depth=30, n_estimators=56, subsample=0.252549911243657; total time=   3.8s\n",
            "n_estimators: 350 max_depth: 2 subsample: 1.0 colsample_bytree: 1.0\n"
          ]
        }
      ],
      "source": [
        "class_XGB = XGBClassifier()\n",
        "\n",
        "search_space = {\"n_estimators\": Integer(50, 350),\n",
        "    \"max_depth\": Integer(2, 30),\n",
        "    \"subsample\": Real(0.05, 1.0),\n",
        "    \"colsample_bytree\": Real(0.05, 1.0)}\n",
        "\n",
        "sc = MinMaxScaler(feature_range=(0, 1))\n",
        "x_train01 = sc.fit_transform(x_model)\n",
        "opt_XGB = BayesSearchCV(estimator = class_XGB, search_spaces=search_space, cv = separation(x_model, y_model, 5, 0.2), n_iter=32, verbose=2, n_jobs=-1)\n",
        "opt_XGB.fit(x_train01, y_model)\n",
        "\n",
        "n_estimators = opt_XGB.best_estimator_.n_estimators\n",
        "max_depth = opt_XGB.best_estimator_.max_depth\n",
        "subsample = opt_XGB.best_estimator_.subsample\n",
        "colsample_bytree = opt_XGB.best_estimator_.colsample_bytree\n",
        "\n",
        "print('n_estimators:', n_estimators,'max_depth:', max_depth, 'subsample:', subsample,'colsample_bytree:', colsample_bytree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Jtr4ezwlZgAT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_score: 0.7021276595744681\n",
            "Accuracy: 0.4396628590947828\n",
            "f1_train: 0.7409860990443095\n",
            "Accuracy_train: 0.5070641382646615\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_score: 0.6977854971775944\n",
            "Accuracy: 0.46367584295261866\n",
            "f1_train: 0.7427237185056473\n",
            "Accuracy_train: 0.5074586848809072\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_score: 0.7121146330872775\n",
            "Accuracy: 0.40727610251203716\n",
            "f1_train: 0.7394656820156386\n",
            "Accuracy_train: 0.5176563619833441\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "f1_score: 0.6990881458966566\n",
            "Accuracy: 0.4437308097082533\n",
            "f1_train: 0.7408774978279756\n",
            "Accuracy_train: 0.5006043573509763\n",
            "f1_score: 0.6999565783760313\n",
            "Accuracy: 0.4509235563041122\n",
            "f1_train: 0.7404430929626411\n",
            "Accuracy_train: 0.5018232806440538\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Random Forest Classification0</th>\n",
              "      <th>Random Forest Classification1</th>\n",
              "      <th>Random Forest Classification2</th>\n",
              "      <th>Random Forest Classification3</th>\n",
              "      <th>Random Forest Classification4</th>\n",
              "      <th>Gradient Boosting Classification0</th>\n",
              "      <th>Gradient Boosting Classification1</th>\n",
              "      <th>Gradient Boosting Classification2</th>\n",
              "      <th>Gradient Boosting Classification3</th>\n",
              "      <th>Gradient Boosting Classification4</th>\n",
              "      <th>XGBoosting Classification0</th>\n",
              "      <th>XGBoosting Classification1</th>\n",
              "      <th>XGBoosting Classification2</th>\n",
              "      <th>XGBoosting Classification3</th>\n",
              "      <th>XGBoosting Classification4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.673436</td>\n",
              "      <td>0.674088</td>\n",
              "      <td>0.667897</td>\n",
              "      <td>0.671807</td>\n",
              "      <td>0.667137</td>\n",
              "      <td>0.757819</td>\n",
              "      <td>0.761186</td>\n",
              "      <td>0.757276</td>\n",
              "      <td>0.757385</td>\n",
              "      <td>0.760209</td>\n",
              "      <td>0.740986</td>\n",
              "      <td>0.742724</td>\n",
              "      <td>0.739466</td>\n",
              "      <td>0.740877</td>\n",
              "      <td>0.740443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.669127</td>\n",
              "      <td>0.662180</td>\n",
              "      <td>0.669561</td>\n",
              "      <td>0.650890</td>\n",
              "      <td>0.663482</td>\n",
              "      <td>0.697351</td>\n",
              "      <td>0.695180</td>\n",
              "      <td>0.712983</td>\n",
              "      <td>0.697351</td>\n",
              "      <td>0.699088</td>\n",
              "      <td>0.702128</td>\n",
              "      <td>0.697785</td>\n",
              "      <td>0.712115</td>\n",
              "      <td>0.699088</td>\n",
              "      <td>0.699957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.294702</td>\n",
              "      <td>0.294885</td>\n",
              "      <td>0.293180</td>\n",
              "      <td>0.293812</td>\n",
              "      <td>0.292484</td>\n",
              "      <td>0.576679</td>\n",
              "      <td>0.584539</td>\n",
              "      <td>0.589173</td>\n",
              "      <td>0.578195</td>\n",
              "      <td>0.577981</td>\n",
              "      <td>0.507064</td>\n",
              "      <td>0.507459</td>\n",
              "      <td>0.517656</td>\n",
              "      <td>0.500604</td>\n",
              "      <td>0.501823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.291709</td>\n",
              "      <td>0.289530</td>\n",
              "      <td>0.291701</td>\n",
              "      <td>0.284991</td>\n",
              "      <td>0.290344</td>\n",
              "      <td>0.459937</td>\n",
              "      <td>0.468787</td>\n",
              "      <td>0.442865</td>\n",
              "      <td>0.476503</td>\n",
              "      <td>0.465518</td>\n",
              "      <td>0.439663</td>\n",
              "      <td>0.463676</td>\n",
              "      <td>0.407276</td>\n",
              "      <td>0.443731</td>\n",
              "      <td>0.450924</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Random Forest Classification0  Random Forest Classification1  \\\n",
              "0                       0.673436                       0.674088   \n",
              "1                       0.669127                       0.662180   \n",
              "2                       0.294702                       0.294885   \n",
              "3                       0.291709                       0.289530   \n",
              "\n",
              "   Random Forest Classification2  Random Forest Classification3  \\\n",
              "0                       0.667897                       0.671807   \n",
              "1                       0.669561                       0.650890   \n",
              "2                       0.293180                       0.293812   \n",
              "3                       0.291701                       0.284991   \n",
              "\n",
              "   Random Forest Classification4  Gradient Boosting Classification0  \\\n",
              "0                       0.667137                           0.757819   \n",
              "1                       0.663482                           0.697351   \n",
              "2                       0.292484                           0.576679   \n",
              "3                       0.290344                           0.459937   \n",
              "\n",
              "   Gradient Boosting Classification1  Gradient Boosting Classification2  \\\n",
              "0                           0.761186                           0.757276   \n",
              "1                           0.695180                           0.712983   \n",
              "2                           0.584539                           0.589173   \n",
              "3                           0.468787                           0.442865   \n",
              "\n",
              "   Gradient Boosting Classification3  Gradient Boosting Classification4  \\\n",
              "0                           0.757385                           0.760209   \n",
              "1                           0.697351                           0.699088   \n",
              "2                           0.578195                           0.577981   \n",
              "3                           0.476503                           0.465518   \n",
              "\n",
              "   XGBoosting Classification0  XGBoosting Classification1  \\\n",
              "0                    0.740986                    0.742724   \n",
              "1                    0.702128                    0.697785   \n",
              "2                    0.507064                    0.507459   \n",
              "3                    0.439663                    0.463676   \n",
              "\n",
              "   XGBoosting Classification2  XGBoosting Classification3  \\\n",
              "0                    0.739466                    0.740877   \n",
              "1                    0.712115                    0.699088   \n",
              "2                    0.517656                    0.500604   \n",
              "3                    0.407276                    0.443731   \n",
              "\n",
              "   XGBoosting Classification4  \n",
              "0                    0.740443  \n",
              "1                    0.699957  \n",
              "2                    0.501823  \n",
              "3                    0.450924  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count = 0\n",
        "XGB_df = x_model[:]\n",
        "XGB_df['Sugar'] = y_model\n",
        "\n",
        "for train_idx, val_idx in cv:\n",
        "    x_train_mod, x_test_mod = x_model.iloc[train_idx], x_model.iloc[val_idx]\n",
        "    y_train_mod, y_test_mod = y_model.iloc[train_idx], y_model.iloc[val_idx]\n",
        "\n",
        "    sc = MinMaxScaler(feature_range=(0, 1))\n",
        "    x_train_mod = sc.fit_transform(x_train_mod)\n",
        "    x_test_mod = sc.transform(x_test_mod)\n",
        "\n",
        "    class_XGB = XGBClassifier(n_estimators = n_estimators, max_depth = max_depth, subsample = subsample, colsample_bytree = colsample_bytree)\n",
        "    class_XGB.fit(x_train_mod, y_train_mod)\n",
        "    y_pred = class_XGB.predict(x_test_mod)\n",
        "    y1_pred = class_XGB.predict(x_train_mod)\n",
        "\n",
        "    XGB_df['Strength_train' + str(count)] = None\n",
        "    XGB_df['Strength_test' + str(count)] = None\n",
        "    XGB_df['Strength_train' + str(count)].iloc[train_idx] = y1_pred\n",
        "    XGB_df['Strength_test' + str(count)].iloc[val_idx] = y_pred\n",
        "\n",
        "    df_error_train['XGBoosting Classification' + str(count)] = metrics(class_XGB, x_train_mod, y_train_mod, y_test_mod, y_pred, y1_pred)\n",
        "    count +=1\n",
        "df_error_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fOax3iYZnc4"
      },
      "source": [
        "## 5. General graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "prFp0WpEZogV"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Random Forest Classification0</th>\n",
              "      <th>Random Forest Classification1</th>\n",
              "      <th>Random Forest Classification2</th>\n",
              "      <th>Random Forest Classification3</th>\n",
              "      <th>Random Forest Classification4</th>\n",
              "      <th>Gradient Boosting Classification0</th>\n",
              "      <th>Gradient Boosting Classification1</th>\n",
              "      <th>Gradient Boosting Classification2</th>\n",
              "      <th>Gradient Boosting Classification3</th>\n",
              "      <th>Gradient Boosting Classification4</th>\n",
              "      <th>XGBoosting Classification0</th>\n",
              "      <th>XGBoosting Classification1</th>\n",
              "      <th>XGBoosting Classification2</th>\n",
              "      <th>XGBoosting Classification3</th>\n",
              "      <th>XGBoosting Classification4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>F1_train</th>\n",
              "      <td>0.673436</td>\n",
              "      <td>0.674088</td>\n",
              "      <td>0.667897</td>\n",
              "      <td>0.671807</td>\n",
              "      <td>0.667137</td>\n",
              "      <td>0.757819</td>\n",
              "      <td>0.761186</td>\n",
              "      <td>0.757276</td>\n",
              "      <td>0.757385</td>\n",
              "      <td>0.760209</td>\n",
              "      <td>0.740986</td>\n",
              "      <td>0.742724</td>\n",
              "      <td>0.739466</td>\n",
              "      <td>0.740877</td>\n",
              "      <td>0.740443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F1_test</th>\n",
              "      <td>0.669127</td>\n",
              "      <td>0.662180</td>\n",
              "      <td>0.669561</td>\n",
              "      <td>0.650890</td>\n",
              "      <td>0.663482</td>\n",
              "      <td>0.697351</td>\n",
              "      <td>0.695180</td>\n",
              "      <td>0.712983</td>\n",
              "      <td>0.697351</td>\n",
              "      <td>0.699088</td>\n",
              "      <td>0.702128</td>\n",
              "      <td>0.697785</td>\n",
              "      <td>0.712115</td>\n",
              "      <td>0.699088</td>\n",
              "      <td>0.699957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Accuracy_train</th>\n",
              "      <td>0.294702</td>\n",
              "      <td>0.294885</td>\n",
              "      <td>0.293180</td>\n",
              "      <td>0.293812</td>\n",
              "      <td>0.292484</td>\n",
              "      <td>0.576679</td>\n",
              "      <td>0.584539</td>\n",
              "      <td>0.589173</td>\n",
              "      <td>0.578195</td>\n",
              "      <td>0.577981</td>\n",
              "      <td>0.507064</td>\n",
              "      <td>0.507459</td>\n",
              "      <td>0.517656</td>\n",
              "      <td>0.500604</td>\n",
              "      <td>0.501823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Accuracy_test</th>\n",
              "      <td>0.291709</td>\n",
              "      <td>0.289530</td>\n",
              "      <td>0.291701</td>\n",
              "      <td>0.284991</td>\n",
              "      <td>0.290344</td>\n",
              "      <td>0.459937</td>\n",
              "      <td>0.468787</td>\n",
              "      <td>0.442865</td>\n",
              "      <td>0.476503</td>\n",
              "      <td>0.465518</td>\n",
              "      <td>0.439663</td>\n",
              "      <td>0.463676</td>\n",
              "      <td>0.407276</td>\n",
              "      <td>0.443731</td>\n",
              "      <td>0.450924</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Random Forest Classification0  Random Forest Classification1  \\\n",
              "F1_train                             0.673436                       0.674088   \n",
              "F1_test                              0.669127                       0.662180   \n",
              "Accuracy_train                       0.294702                       0.294885   \n",
              "Accuracy_test                        0.291709                       0.289530   \n",
              "\n",
              "                Random Forest Classification2  Random Forest Classification3  \\\n",
              "F1_train                             0.667897                       0.671807   \n",
              "F1_test                              0.669561                       0.650890   \n",
              "Accuracy_train                       0.293180                       0.293812   \n",
              "Accuracy_test                        0.291701                       0.284991   \n",
              "\n",
              "                Random Forest Classification4  \\\n",
              "F1_train                             0.667137   \n",
              "F1_test                              0.663482   \n",
              "Accuracy_train                       0.292484   \n",
              "Accuracy_test                        0.290344   \n",
              "\n",
              "                Gradient Boosting Classification0  \\\n",
              "F1_train                                 0.757819   \n",
              "F1_test                                  0.697351   \n",
              "Accuracy_train                           0.576679   \n",
              "Accuracy_test                            0.459937   \n",
              "\n",
              "                Gradient Boosting Classification1  \\\n",
              "F1_train                                 0.761186   \n",
              "F1_test                                  0.695180   \n",
              "Accuracy_train                           0.584539   \n",
              "Accuracy_test                            0.468787   \n",
              "\n",
              "                Gradient Boosting Classification2  \\\n",
              "F1_train                                 0.757276   \n",
              "F1_test                                  0.712983   \n",
              "Accuracy_train                           0.589173   \n",
              "Accuracy_test                            0.442865   \n",
              "\n",
              "                Gradient Boosting Classification3  \\\n",
              "F1_train                                 0.757385   \n",
              "F1_test                                  0.697351   \n",
              "Accuracy_train                           0.578195   \n",
              "Accuracy_test                            0.476503   \n",
              "\n",
              "                Gradient Boosting Classification4  XGBoosting Classification0  \\\n",
              "F1_train                                 0.760209                    0.740986   \n",
              "F1_test                                  0.699088                    0.702128   \n",
              "Accuracy_train                           0.577981                    0.507064   \n",
              "Accuracy_test                            0.465518                    0.439663   \n",
              "\n",
              "                XGBoosting Classification1  XGBoosting Classification2  \\\n",
              "F1_train                          0.742724                    0.739466   \n",
              "F1_test                           0.697785                    0.712115   \n",
              "Accuracy_train                    0.507459                    0.517656   \n",
              "Accuracy_test                     0.463676                    0.407276   \n",
              "\n",
              "                XGBoosting Classification3  XGBoosting Classification4  \n",
              "F1_train                          0.740877                    0.740443  \n",
              "F1_test                           0.699088                    0.699957  \n",
              "Accuracy_train                    0.500604                    0.501823  \n",
              "Accuracy_test                     0.443731                    0.450924  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_error_train.index = ['F1_train', 'F1_test', 'Accuracy_train', 'Accuracy_test']\n",
        "df_error_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6VZ_MekRZuCD"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1_train_mean</th>\n",
              "      <th>F1_train_std</th>\n",
              "      <th>F1_test_mean</th>\n",
              "      <th>F1_test_std</th>\n",
              "      <th>Accuracy_train_mean</th>\n",
              "      <th>Accuracy_train_std</th>\n",
              "      <th>Accuracy_test_mean</th>\n",
              "      <th>Accuracy_test_std</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Gradient Boosting Classification</th>\n",
              "      <td>0.758775</td>\n",
              "      <td>0.001800</td>\n",
              "      <td>0.700391</td>\n",
              "      <td>0.007174</td>\n",
              "      <td>0.581313</td>\n",
              "      <td>0.005350</td>\n",
              "      <td>0.462722</td>\n",
              "      <td>0.012615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Forest Classification</th>\n",
              "      <td>0.670873</td>\n",
              "      <td>0.003185</td>\n",
              "      <td>0.663048</td>\n",
              "      <td>0.007552</td>\n",
              "      <td>0.293813</td>\n",
              "      <td>0.001013</td>\n",
              "      <td>0.289655</td>\n",
              "      <td>0.002768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XGBoosting Classification</th>\n",
              "      <td>0.740899</td>\n",
              "      <td>0.001183</td>\n",
              "      <td>0.702215</td>\n",
              "      <td>0.005756</td>\n",
              "      <td>0.506921</td>\n",
              "      <td>0.006735</td>\n",
              "      <td>0.441054</td>\n",
              "      <td>0.020971</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  F1_train_mean  F1_train_std  F1_test_mean  \\\n",
              "Class                                                                         \n",
              "Gradient Boosting Classification       0.758775      0.001800      0.700391   \n",
              "Random Forest Classification           0.670873      0.003185      0.663048   \n",
              "XGBoosting Classification              0.740899      0.001183      0.702215   \n",
              "\n",
              "                                  F1_test_std  Accuracy_train_mean  \\\n",
              "Class                                                                \n",
              "Gradient Boosting Classification     0.007174             0.581313   \n",
              "Random Forest Classification         0.007552             0.293813   \n",
              "XGBoosting Classification            0.005756             0.506921   \n",
              "\n",
              "                                  Accuracy_train_std  Accuracy_test_mean  \\\n",
              "Class                                                                      \n",
              "Gradient Boosting Classification            0.005350            0.462722   \n",
              "Random Forest Classification                0.001013            0.289655   \n",
              "XGBoosting Classification                   0.006735            0.441054   \n",
              "\n",
              "                                  Accuracy_test_std  \n",
              "Class                                                \n",
              "Gradient Boosting Classification           0.012615  \n",
              "Random Forest Classification               0.002768  \n",
              "XGBoosting Classification                  0.020971  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_error_train_1 = df_error_train.transpose()\n",
        "f_get_name = lambda x: x[:-1]\n",
        "df_error_train_1['Class'] = df_error_train_1.index\n",
        "df_error_train_1['Class'] = df_error_train_1['Class'].apply(f_get_name)\n",
        "df_error_train_1 = df_error_train_1.groupby('Class').agg(['mean', 'std'])\n",
        "df_error_train_1.columns = ['_'.join(col).rstrip('_') for col in df_error_train_1.columns.values] \n",
        "df_error_train_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MjadzZGoZvvr"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x12168ab90>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.patches as mpatches\n",
        "\n",
        "barWidth = 0.4\n",
        "\n",
        "br1 = np.arange(3)\n",
        "br2 = [x + barWidth for x in br1]\n",
        "br3 =  np.arange(3)\n",
        "br4 = [x + barWidth for x in br3]\n",
        "\n",
        "fig, ((ax1, ax2)) = plt.subplots(nrows=1, ncols=2, sharex=True, figsize=(20, 6))\n",
        "\n",
        "ax1.bar(br1, df_error_train_1['F1_train_mean'], color =colors[0], width = barWidth, label ='F1_train', yerr = df_error_train_1['F1_train_std'])\n",
        "ax1.bar(br2, df_error_train_1['F1_test_mean'], color =colors[1], width = barWidth, label ='F1_validation', yerr = df_error_train_1['F1_test_std'])\n",
        "\n",
        "ax2.bar(br3, df_error_train_1['Accuracy_train_mean'], color =colors[4], width = barWidth, label ='Accuracy_train', yerr = df_error_train_1['Accuracy_train_std'])\n",
        "ax2.bar(br4, df_error_train_1['Accuracy_test_mean'], color =colors[3], width = barWidth, label ='Accuracy_validation', yerr = df_error_train_1['Accuracy_test_std'])\n",
        "\n",
        "plt.xticks(br1, ['GBC','RFC','XGB'], fontsize = 12)\n",
        "\n",
        "ax1.grid(color='#C3C6BA', linewidth=0.3)\n",
        "ax2.grid(color='#C3C6BA', linewidth=0.3)\n",
        "\n",
        "\n",
        "ax1.legend(fontsize = 12)\n",
        "ax2.legend(fontsize = 12)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['strength.pkl']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "joblib.dump(class_GBC, 'strength.pkl')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "9D_WNHUdWdSW",
        "ClbHv28CXNWu",
        "5RUUYh0dXc_E",
        "NiB_N6vEXl8E",
        "ZgYn-6KPXw8T",
        "nlMEsSGmYWEy",
        "2DQ62X2nYrqt",
        "Fe5Xj7N3ZUvJ"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
